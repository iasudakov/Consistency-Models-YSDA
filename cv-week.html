<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>91f338d7018143688fb7526b6e18c606</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div id="c3bb8ead" class="cell markdown" id="c3bb8ead">
<h1 id="cv-week-итоговое-задание">CV Week: Итоговое задание</h1>
<p>На лекции и семинаре мы разбирали как дистиллировать многошаговую
диффузионную модель в малошагового студента, и тем самым будет работать
на порядок быстрее учителя.</p>
<p>Один из подходов, который мы разбирали <em>Consistency
Distillation</em>. В этом задании, мы закрепим материал, который был на
лекции и семинаре и реализуем этот фреймворк, затрагивая различные
нюансы.</p>
<p>В этом задании мы будем дистиллировать модель <em>Stable Diffusion
1.5 (SD1.5)</em> для генерации картинок по текстовому описанию.</p>
<p>Вам предстоит выполнить 8 небольших заданий, которые приведут нас к
неплохой модели для генерации картинок за 4 шага, работая в органиченных
условиях колаба.</p>
</div>
<div id="585e5265" class="cell code" data-execution_count="2"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:09:41.705629Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:09:41.704906Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:09:50.029435Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:09:50.028627Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:09:41.705594Z&quot;}"
id="585e5265" data-outputId="a665b27c-3e95-4250-e27e-253d50dd5947">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># torch 2.4.1+cu124</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install diffusers<span class="op">==</span><span class="fl">0.30.3</span> peft<span class="op">==</span><span class="fl">0.8.2</span> huggingface_hub<span class="op">==</span><span class="fl">0.23.4</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: diffusers==0.30.3 in /opt/conda/lib/python3.10/site-packages (0.30.3)
Requirement already satisfied: peft==0.8.2 in /opt/conda/lib/python3.10/site-packages (0.8.2)
Requirement already satisfied: huggingface_hub==0.23.4 in /opt/conda/lib/python3.10/site-packages (0.23.4)
Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers==0.30.3) (7.0.0)
Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers==0.30.3) (3.15.1)
Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from diffusers==0.30.3) (1.26.4)
Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from diffusers==0.30.3) (2024.5.15)
Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers==0.30.3) (2.32.3)
Requirement already satisfied: safetensors&gt;=0.3.1 in /opt/conda/lib/python3.10/site-packages (from diffusers==0.30.3) (0.4.5)
Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers==0.30.3) (10.3.0)
Requirement already satisfied: packaging&gt;=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (21.3)
Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (5.9.3)
Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (6.0.2)
Requirement already satisfied: torch&gt;=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (2.4.0)
Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (4.46.3)
Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (4.66.4)
Requirement already satisfied: accelerate&gt;=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (1.1.1)
Requirement already satisfied: fsspec&gt;=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.23.4) (2024.6.0)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.23.4) (4.12.2)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging&gt;=20.0-&gt;peft==0.8.2) (3.1.2)
Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch&gt;=1.13.0-&gt;peft==0.8.2) (1.13.3)
Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch&gt;=1.13.0-&gt;peft==0.8.2) (3.3)
Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch&gt;=1.13.0-&gt;peft==0.8.2) (3.1.4)
Requirement already satisfied: zipp&gt;=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata-&gt;diffusers==0.30.3) (3.19.2)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;diffusers==0.30.3) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;diffusers==0.30.3) (3.7)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;diffusers==0.30.3) (1.26.18)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;diffusers==0.30.3) (2024.6.2)
Requirement already satisfied: tokenizers&lt;0.21,&gt;=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers-&gt;peft==0.8.2) (0.20.3)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2-&gt;torch&gt;=1.13.0-&gt;peft==0.8.2) (2.1.5)
Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy-&gt;torch&gt;=1.13.0-&gt;peft==0.8.2) (1.3.0)
</code></pre>
</div>
</div>
<div id="67e4aafa" class="cell markdown" id="67e4aafa">
<h2 id="теормин">Теормин</h2>
<hr />
<h3 id="диффузионные-модели">Диффузионные модели</h3>
<p>Задан прямой диффузионный процесс, который переводит чистые картинки
в шум с помощью распределения <span
class="math inline"><em>q</em>(<strong>x</strong><sub><em>t</em></sub>|<strong>x</strong><sub>0</sub>) = <em>N</em>(<strong>x</strong><sub><em>t</em></sub>|<em>α</em><sub><em>t</em></sub><strong>x</strong><sub>0</sub>,<em>σ</em><sub><em>t</em></sub><sup>2</sup><em>I</em>)</span></p>
<p>Таким образом, мы можем получаться зашумленные картинки по следующей
формуле: <span
class="math inline"><strong>x</strong><sub><em>t</em></sub> = <em>α</em><sub><em>t</em></sub><strong>x</strong><sub>0</sub> + <em>σ</em><sub><em>t</em></sub><em>ϵ</em></span>,
где <span
class="math inline"><em>ϵ</em> ∼ <em>N</em>(0,<em>I</em>)</span>
<strong>(1)</strong></p>
<p><span
class="math inline"><em>α</em><sub><em>t</em></sub>, <em>σ</em><sub><em>t</em></sub></span>
задают процесс зашумления. Здесь мы будем иметь дело с <em>variance
preserving (VP)</em> процессом: <span
class="math inline"><em>α</em><sub><em>t</em></sub><sup>2</sup> = 1 − <em>σ</em><sub><em>t</em></sub><sup>2</sup></span>.</p>
<p>Диффузионная модель (ДМ) пытается решить обратную задачу: из шума
порождать новые картинки. Важно, что диффузионный процесс можно описать
следующим обыкновенным дифференциальным уравнением (ОДУ):</p>
<p><span class="math inline">$dx = \left[ f(\mathbf{x}, t) - \frac{1}{2}
\nabla_{\mathbf{x}_t} \log p_t(\mathbf{x}) \right] dt$</span>,
<strong>(2)</strong></p>
<p>где <span
class="math inline"><em>f</em>(<strong>x</strong>,<em>t</em>)</span>
известен из заданного процесса зашумления, а <span
class="math inline">∇<sub><strong>x</strong><sub><em>t</em></sub></sub>log <em>p</em><sub><em>t</em></sub>(<strong>x</strong><sub><em>t</em></sub>)</span>
(<em>скор функцию</em>) оцениваем с помощью нейросети: <span
class="math inline"><em>s</em><sub><em>θ</em></sub>(<strong>x</strong><sub><em>t</em></sub>,<em>t</em>) ≈ ∇<sub><strong>x</strong><sub><em>t</em></sub></sub>log <em>p</em><sub><em>t</em></sub>(<strong>x</strong><sub><em>t</em></sub>)</span>.
Таким образом, имея оценку на <span
class="math inline">∇<sub><strong>x</strong><sub><em>t</em></sub></sub>log <em>p</em><sub><em>t</em></sub>(<strong>x</strong>)</span>,
мы можем решить это ОДУ, стартуя со случайного шума, и получить
картинку.</p>
<p><strong>SD1.5</strong> использует <em><span
class="math inline"><em>ϵ</em></span>-параметризацию</em>, т.е., UNet
пытается предсказать шум, который мы добавили на картинку по формуле
<strong>(1)</strong>. Оценку скор функции можно получить, пользуясь
результатом, вытекающим из формулы Твидди: <span
class="math inline">$s_\theta(\mathbf{x}_t, t) = -
\frac{\epsilon_\theta(\mathbf{x}_t, t)} { \sigma_t}$</span></p>
<p>Чтобы решить ОДУ <strong>(2)</strong>, нам нужно воспользоваться
каким-то численным методом (солвером). В этом задании мы будем работать
с не самым эффектным, но самым популярным солвером:
<strong>DDIM</strong>, который является адаптированным методом Эйлера
под диффузионный ОДУ.</p>
<p>Для VP процесса переход с помощью DDIM с шага <span
class="math inline"><em>t</em></span> на <span
class="math inline"><em>s</em></span> можно сделать следующим
образом:</p>
<p>$ x_s = DDIM(\mathbf{x}<em>t, t, s) = \alpha_s \cdot
\left(\frac{\mathbf{x}<em>t - \sigma_t \epsilon</em>\theta}{\alpha_t}
\right) + \sigma_s \epsilon</em>\theta $</p>
<p>Этот переход можно интерпретировать так: получаем оценку на чистую
картинку <span class="math inline"><strong>x</strong><sub>0</sub></span>
на шаге <span class="math inline"><em>t</em></span>, используя <span
class="math inline">$\frac{\mathbf{x}_t - \sigma_t
\epsilon_\theta}{\alpha_t}$</span>, а потом снова зашумляем эту оценку
на шаг <span class="math inline"><em>s</em></span> по формуле
<strong>(1)</strong>, но только используем не случайный шум, а шум
предсказанный моделью <span
class="math inline"><em>ϵ</em><sub><em>θ</em></sub></span>.</p>
<p><em>Используя DDIM для SD1.5, можем получать хорошие картинки за 50
шагов.</em></p>
<p><strong>SD1.5</strong> - латентная ДМ, т.е. модель работает не в
пиксельном пространстве, а в латентном пространстве
<strong>VAE</strong>. Таким образом SD1.5 состоит из следующих
компонент:</p>
<p>1) <strong>VAE</strong> - переводит <span
class="math inline">3 × 512 × 512</span> картинки в латенты <span
class="math inline">4 × 64 × 64</span> и может декодировать их обратно в
картинки. 2) <strong>Текстовый энкодер</strong> - извлекает текстовые
признаки из промпта. Эти признаки будут подаваться в диффузионную
модель, чтобы дать модели информацию, что именно хотим сгенерировать 3)
<strong>Диффузионная модель</strong> - UNet, работающий на "латентных
картинках" <span class="math inline">4 × 64 × 64</span>.</p>
<hr />
<h3 id="консистенси-модели"><a
href="https://arxiv.org/pdf/2303.01469">Консистенси модели</a></h3>
<p>Главная цель дистилляции диффузии - уменьшить количество шагов ДМ,
при этом сохранив высокое качество картинок.</p>
<p><strong>Консистенси модели (Consistency Models | CM)</strong> - класс
моделей, где мы хотим выучить "консистенси функцию" <span
class="math inline"><em>f</em><sub><em>θ</em></sub>(<strong>x</strong><sub><em>t</em></sub>)</span>
- с любой точки <span
class="math inline"><strong>x</strong><sub><em>t</em></sub></span>
траектории диффузионного ОДУ <strong>(2)</strong> сразу предсказывать
<span class="math inline"><strong>x</strong><sub>0</sub></span> (чистые
данные) за один шаг. Если мы идеально выучим консистенси функцию, то
сможем шагать из чистого шума сразу в картинку, что супер эффективно в
отличии от генерации ДМ.</p>
<p>Отметим, что консистенси модель можно учить как независимую
генеративную модель, без предобученной ДМ, и в <em>задании 3</em> вам
предстоит подумать, как это можно сделать.</p>
<p><br></p>
<div>

<img src="https://storage.yandexcloud.net/yandex-research/cvweek-cd-task-images/cd-idea.jpg" width="600"/>
</div>
<p><strong>Консистенси дистилляция (Consistency Distillation |
CD)</strong> - подход, когда для обучения CM, мы используем
предобученную ДМ. ДМ нам дает качественную инициализацию модели и уже
обученную скор функцию, что сильно упрощает сходимость консистенси
моделей.</p>
<h4 id="обучение-cm">Обучение CM</h4>
<div>
<img src="https://storage.yandexcloud.net/yandex-research/cvweek-cd-task-images/cd-training.jpg" width="600"/>
</div>
<p>Главный принцип обучения консистенси моделей заключается в попытке
удовлетворить <em>self-consistency</em> св-ву: выход CM на двух соседних
точках траектории <span
class="math inline"><strong>x</strong><sub><em>t</em></sub></span> и
<span
class="math inline"><strong>x</strong><sub><em>t</em> − 1</sub></span>
должен совпадать по какой-то мере близости, например L2 расстояние:
<span
class="math inline">∥<em>f</em><sub><em>θ</em></sub>(<strong>x</strong><sub><em>t</em> − 1</sub>) − <em>f</em><sub><em>θ</em></sub>(<strong>x</strong><sub><em>t</em></sub>)∥<sub>2</sub><sup>2</sup></span>.</p>
<p>Заметим, что self-consistency св-во удовлетворить очень просто без
какого-либо обучения, взяв, например <span
class="math inline"><em>f</em><sub><em>θ</em></sub>(<strong>x</strong><sub><em>t</em></sub>) ≡ 0</span>.</p>
<p>Поэтому, чтобы избежать вырожденных решений, нам необходимо выставить
граничное условие (boundary condition), которое будет требовать, чтобы в
самой левой точке траектории около <span
class="math inline"><em>t</em> = 0</span>, модель предсказывала
картинку, которую получает на вход: <span
class="math inline"><em>f</em><sub><em>θ</em></sub>(<strong>x</strong><sub>0</sub>) = <strong>x</strong><sub>0</sub></span>.</p>
<p><strong>Практическое замечание:</strong> Для обеих точек траектории
мы применяем одну и ту же модель <span
class="math inline"><em>f</em><sub><em>θ</em></sub>(⋅)</span>. Но выход
модели на шаге <span class="math inline"><em>t</em> − 1</span> является
"таргетом" для выхода модели на шаге <span
class="math inline"><em>t</em></span> и поэтому выполнение модели для
шага <span class="math inline"><em>t</em> − 1</span> делается в
<em>torch.no_grad</em> режиме.</p>
<p><strong>Как получать две соседние точки на траектории
ОДУ?</strong></p>
<p>Берем случайную картинку <span
class="math inline"><strong>x</strong><sub>0</sub></span> из
датасета.</p>
<p>Точку <span
class="math inline"><strong>x</strong><sub><em>t</em></sub></span>
получаем с помощью прямого процесса зашумления: <span
class="math inline"><strong>x</strong><sub><em>t</em></sub> = <em>q</em>(<strong>x</strong><sub><em>t</em></sub>|<strong>x</strong><sub>0</sub>)</span></p>
<p>Чтобы получить соседнюю точку <span
class="math inline"><strong>x</strong><sub><em>t</em> − 1</sub></span>,
нам нужно сделать шаг по траектории ОДУ, используя, например, DDIM
солвер.</p>
<p>В консистенси дистилляции, мы делаем шаг предобученной ДМ: <span
class="math inline"><strong>x</strong><sub><em>t</em> − 1</sub> = <em>D</em><em>D</em><em>I</em><em>M</em>(<em>ϵ</em><sub><em>θ</em></sub>(<strong>x</strong><sub><em>t</em></sub>,<em>t</em>),<strong>x</strong><sub><em>t</em></sub>,<em>t</em>,<em>t</em>−1)</span></p>
<p><strong>Важно:</strong> на практике мы можем брать не соседние шаги
<span class="math inline"><em>t</em></span> и <span
class="math inline"><em>t</em> − 1</span>, а с некоторым интервалом,
например 20 шагов. Размер интервала влияет на bias/variance trade-off в
консистенси обучении: больше интервал между шагами - больше смещение, но
меньше дисперсия, и наоборот. Для простоты в этом задании мы зафиксируем
интервал - 20 шагов, но во многих работах размер интервала динамически
меняется по ходу обучения.</p>
</div>
<div id="c18dffaf" class="cell code" data-execution_count="3"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:09:50.286507Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:09:50.286133Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:10:08.169565Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:10:08.168668Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:09:50.286463Z&quot;}"
id="c18dffaf">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> csv</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> diffusers <span class="im">import</span> StableDiffusionPipeline, LCMScheduler, UNet2DConditionModel, DDIMScheduler</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> peft <span class="im">import</span> LoraConfig, get_peft_model, get_peft_model_state_dict</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> diffusers <span class="im">import</span> StableDiffusionPipeline</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span></code></pre></div>
<div class="output stream stderr">
<pre><code>The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb5"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;7db8c9318e034d8dbfb0f3c6580c5634&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<div id="669d0a3a" class="cell code" data-execution_count="4"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:10:08.171840Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:10:08.171332Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:10:08.184069Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:10:08.183227Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:10:08.171811Z&quot;}"
id="669d0a3a">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#---------------------</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization utils</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">#---------------------</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_images(images):</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="bu">len</span>(images) <span class="op">==</span> <span class="dv">4</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">3</span>))</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, image <span class="kw">in</span> <span class="bu">enumerate</span>(images):</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">1</span>, <span class="dv">4</span>, i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        plt.imshow(image)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        plt.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    plt.subplots_adjust(wspace<span class="op">=-</span><span class="fl">0.01</span>, hspace<span class="op">=-</span><span class="fl">0.01</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Tensor utils</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_into_tensor(a, t, x_shape):</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    b, <span class="op">*</span>_ <span class="op">=</span> t.shape</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> a.gather(<span class="op">-</span><span class="dv">1</span>, t)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out.reshape(b, <span class="op">*</span>((<span class="dv">1</span>,) <span class="op">*</span> (<span class="bu">len</span>(x_shape) <span class="op">-</span> <span class="dv">1</span>)))</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="co">#---------------</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Dataset utils</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="co">#---------------</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> COCODataset(torch.utils.data.Dataset):</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, root_dir, subset_name<span class="op">=</span><span class="st">&quot;train2014_5k&quot;</span>, transform<span class="op">=</span><span class="va">None</span>, max_cnt<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a><span class="co">        Arguments:</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="co">            root_dir (string): Директория с картинками</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a><span class="co">            transform (callable, optional): преобразования, применимые к картинкам</span></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.root_dir <span class="op">=</span> root_dir</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.extensions <span class="op">=</span> (</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;.jpg&quot;</span>,</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;.jpeg&quot;</span>,</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;.png&quot;</span>,</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;.ppm&quot;</span>,</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;.bmp&quot;</span>,</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;.pgm&quot;</span>,</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;.tif&quot;</span>,</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;.tiff&quot;</span>,</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;.webp&quot;</span>,</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>        sample_dir <span class="op">=</span> os.path.join(root_dir, subset_name)</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Собираем пути до картинок</span></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.samples <span class="op">=</span> <span class="bu">sorted</span>(</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>            [</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>                os.path.join(sample_dir, fname)</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> fname <span class="kw">in</span> os.listdir(sample_dir)</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> fname[<span class="op">-</span><span class="dv">4</span>:] <span class="kw">in</span> <span class="va">self</span>.extensions</span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>            key<span class="op">=</span><span class="kw">lambda</span> x: x.split(<span class="st">&quot;/&quot;</span>)[<span class="op">-</span><span class="dv">1</span>].split(<span class="st">&quot;.&quot;</span>)[<span class="dv">0</span>],</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.samples <span class="op">=</span> (</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.samples <span class="cf">if</span> max_cnt <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">self</span>.samples[:max_cnt]</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>        )  <span class="co">#</span></span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Собираем промпты</span></span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.captions <span class="op">=</span> {}</span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>            os.path.join(root_dir, <span class="ss">f&quot;</span><span class="sc">{</span>subset_name<span class="sc">}</span><span class="ss">.csv&quot;</span>), newline<span class="op">=</span><span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span></span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>        ) <span class="im">as</span> csvfile:</span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>            spamreader <span class="op">=</span> csv.reader(csvfile, delimiter<span class="op">=</span><span class="st">&quot;,&quot;</span>)</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i, row <span class="kw">in</span> <span class="bu">enumerate</span>(spamreader):</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> i <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">continue</span></span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.captions[row[<span class="dv">1</span>]] <span class="op">=</span> row[<span class="dv">2</span>]</span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.samples)</span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> torch.is_tensor(idx):</span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>            idx <span class="op">=</span> idx.tolist()</span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a>        sample_path <span class="op">=</span> <span class="va">self</span>.samples[idx]</span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a>        sample <span class="op">=</span> Image.<span class="bu">open</span>(sample_path).convert(<span class="st">&quot;RGB&quot;</span>)</span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.transform:</span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a>            sample <span class="op">=</span> <span class="va">self</span>.transform(sample)</span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;image&quot;</span>: sample,</span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;text&quot;</span>: <span class="va">self</span>.captions[os.path.basename(sample_path)],</span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;idxs&quot;</span>: idx, }</span></code></pre></div>
</div>
<div id="62860269" class="cell markdown" id="&quot;62860269&quot;">
<h1 id="модель-учителя-sd15">Модель учителя (SD1.5)</h1>
</div>
<div id="8ce973eb" class="cell markdown" id="8ce973eb">
<h2 id="задание-1">Задание №1</h2>
<p>Давайте для начала загрузим модель <a
href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5">StableDiffusion
1.5</a> и сгенерируем ей картинки за 50 шагов.</p>
<p><strong>Важно:</strong> для экономии памяти, загружаем все компоненты
модели в FP16. Не забываем положить модель на GPU.</p>
</div>
<div id="4e46016d" class="cell code" data-execution_count="5"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:49,&quot;referenced_widgets&quot;:[&quot;be4128fea37e4b80b86233a37bab596b&quot;,&quot;fa46b9cab9894399bfbf79909edeaab0&quot;,&quot;8ebbda4c01314465816c5f1a79603443&quot;,&quot;e87ba74d231a42ecb7885a49046464aa&quot;,&quot;821cc707a58543ccbcda2d8dfa1745e7&quot;,&quot;db6252e6e8b8486bba77beb2fc18d739&quot;,&quot;666ba9007dbf4f75811e02febc5f1386&quot;,&quot;03c8e5bbd1cf448781d850c87ed9a17b&quot;,&quot;b287cacce7d04e5ba8d1eb33dfcc7231&quot;,&quot;8966642f7d094c1591efcaf826a93bda&quot;,&quot;c1d94806847c4e488840fbbe3a1c12b5&quot;]}"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:10:12.150921Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:10:12.150278Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:10:33.762815Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:10:33.761743Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:10:12.150886Z&quot;}"
id="4e46016d" data-outputId="6cc1d2cd-c8ca-496e-81b1-24d585ae480e">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> diffusers <span class="im">import</span> StableDiffusionPipeline</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>model_id <span class="op">=</span> <span class="st">&quot;sd-legacy/stable-diffusion-v1-5&quot;</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> StableDiffusionPipeline.from_pretrained(model_id, torch_dtype<span class="op">=</span>torch.float16)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipe.to(<span class="st">&quot;cuda&quot;</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Проверяем, что все компоненты модели в FP16 и на cuda</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> pipe.unet.dtype <span class="op">==</span> torch.float16 <span class="kw">and</span> pipe.unet.device.<span class="bu">type</span> <span class="op">==</span> <span class="st">&#39;cuda&#39;</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> pipe.vae.dtype <span class="op">==</span> torch.float16 <span class="kw">and</span> pipe.vae.device.<span class="bu">type</span> <span class="op">==</span> <span class="st">&#39;cuda&#39;</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> pipe.text_encoder.dtype <span class="op">==</span> torch.float16 <span class="kw">and</span> pipe.text_encoder.device.<span class="bu">type</span> <span class="op">==</span> <span class="st">&#39;cuda&#39;</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Заменяем дефолтный сэмплер на DDIM</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>pipe.scheduler <span class="op">=</span> DDIMScheduler.from_config(pipe.scheduler.config, timestep_spacing<span class="op">=</span><span class="st">&quot;trailing&quot;</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>pipe.scheduler.timesteps <span class="op">=</span> pipe.scheduler.timesteps.cuda()</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>pipe.scheduler.alphas_cumprod <span class="op">=</span> pipe.scheduler.alphas_cumprod.cuda()</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Отдельно извлечем модель учителя, которую потом будем дистиллировать</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>teacher_unet <span class="op">=</span> pipe.unet</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb8"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;65f429a8ee6646df8f7c3ff74c35664f&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb9"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;e7b8777947f44ee79d06bf1527c9fdd0&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb10"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;09a74ba807ab48a18b078b9872670ad7&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb11"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;fbd7fb01e933415dac62d8c37ee739fb&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb12"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;b80a7f5bdf3f4471a10a7a8338896ae9&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb13"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;323b4c5eeed043e0948de2b0b11b9673&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb14"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;fac2af2d116e40fb8fbae9e4cc9e0c5d&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb15"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;ff95a62a240d478cb24dcda5db447811&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb16"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;bbe2c74899574dc1abc8584a241c4b48&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb17"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;672aadf1b32e4cf999f2740388b85cf1&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb18"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;0ee918cc23dc47de814343cd8792cb0c&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb19"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;5fab6340d4cc4def91e0fb8d6d311869&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb20"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;2054f4f08a7444b1883cf5e043de37cf&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb21"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;bce0c604edc346ccbabb80d806718b7e&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb22"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;b659e17602f74404aee1ed943bc8f4f0&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb23"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;a123f1d4301b442db16101e815f9d44f&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb24"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;8bdcd5f652ab44eb8c38ccc706b22fec&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<div id="20cb66c9" class="cell markdown" id="20cb66c9">
<p>Теперь сгенерируем картинки за 50 шагов. Вам нужно написать вызов
pipe и передать в него промпт, число шагов генерации, генератор
случайных чисел, гайденс скейл и указать, чтобы сгенерировалось 4
картинки на промпт.</p>
</div>
<div id="d5bb382b" class="cell code" data-execution_count="6"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:260,&quot;referenced_widgets&quot;:[&quot;62cfd46df3a640a1b9f24b1e1c05a69a&quot;,&quot;c2300aa882a3445893bb76aad5eb02b8&quot;,&quot;9c752c4bb2f641278156d3e59a059c5d&quot;,&quot;a1b07d2a04bc4110bb1e12590da36de3&quot;,&quot;af95663794604128bb8713ee4c4c42d5&quot;,&quot;9ccb932c81034b86b498aff6e8ec5411&quot;,&quot;2fd6ba1b3a404aecbb0dd8de5c92d8ea&quot;,&quot;d095c4214e74401992bfd6a311b3e1e4&quot;,&quot;2271c0f6b0ad4afb9bbea1ed7fe820ea&quot;,&quot;9340ab2e10d740c6959110fe15d5c1c1&quot;,&quot;2213af19628e4eb785f4f272e2d71ff4&quot;]}"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:10:33.765362Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:10:33.764946Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:11:01.334567Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:11:01.333767Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:10:33.765317Z&quot;}"
id="d5bb382b" data-outputId="c0996de4-5fcc-49e6-8598-4f36ca780708">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">&quot;A sad puppy with large eyes&quot;</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>guidance_scale <span class="op">=</span> <span class="fl">7.5</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>generator <span class="op">=</span> torch.Generator(<span class="st">&#39;cuda&#39;</span>).manual_seed(<span class="dv">1</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> pipe(prompt, num_inference_steps<span class="op">=</span><span class="dv">50</span>, guidance_scale<span class="op">=</span>guidance_scale, generator<span class="op">=</span>generator, num_images_per_prompt<span class="op">=</span><span class="dv">4</span>).images</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>visualize_images(images)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb26"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;15ce99e8c95744e8a8f19652e63380aa&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/a4e5348d4acd9771a21a508ffa2ea8a0ee5e0972.png" /></p>
</div>
</div>
<div id="09c8a547" class="cell markdown" id="09c8a547">
<p>Давайте посмотрим, что выдаст модель за 4 шага. Все то же самое, что
и выше, просто поменяем число шагов.</p>
</div>
<div id="06e66279" class="cell code" data-execution_count="7"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:260,&quot;referenced_widgets&quot;:[&quot;d0cbda3e17c94691804f17a7f51d6c9e&quot;,&quot;8e354bb8fa7e426c8b16a3e052cdb54e&quot;,&quot;4ef9796d0f754032b38d4fa7a0d93c2f&quot;,&quot;86e504cecf864b3a8b88aa48cbfdbea9&quot;,&quot;831cd26ea13d4a7aa150a3bfc1a1df46&quot;,&quot;1add462a3ba7419cba63c2156f6a0068&quot;,&quot;e5cd13fef2954eeda0e939576f50ca58&quot;,&quot;23636a14450f4c1ba63abb0143b85096&quot;,&quot;de167031cfc64512b308fc5147e71d24&quot;,&quot;d947127f4dad418d8d433ffd24654387&quot;,&quot;5b971ddffe2d487a82599984a10fab01&quot;]}"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:11:01.336111Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:11:01.335803Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:11:05.140537Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:11:05.139731Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:11:01.336066Z&quot;}"
id="06e66279" data-outputId="06a9d64e-3ff8-4523-d587-c67901aeebd0">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>generator <span class="op">=</span> torch.Generator(<span class="st">&#39;cuda&#39;</span>).manual_seed(<span class="dv">1</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> pipe(prompt, num_inference_steps<span class="op">=</span><span class="dv">4</span>, guidance_scale<span class="op">=</span>guidance_scale, generator<span class="op">=</span>generator, num_images_per_prompt<span class="op">=</span><span class="dv">4</span>).images</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>visualize_images(images)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb28"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;80c8b1a52479401692fbdd525c35acad&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/501d1e3fb16a13b6d49b391cfaf50bfa5ea49ce8.png" /></p>
</div>
</div>
<div id="b0cb5003" class="cell markdown" id="b0cb5003">
<p>На 4 шагах картинки получаются размазанными. Давайте постараемся
починить их.</p>
</div>
<div id="82774c59" class="cell markdown" id="82774c59">
<h2 id="создаем-датасет">Создаем датасет</h2>
<p>Чтобы ДЗ было легко выполнимым на colab, мы будем учить консистенси
модели на небольшой обучающей выборке из 5000 пар текст-картинка из COCO
датасета. Интересное свойство консистенси моделей - они могут сходиться
до адекватного качества за несколько сотен шагов. Качество все еще будет
не идеальным, но фазовый переход уже должен быть заметен.</p>
<p>Данные можно загрузить с помощью команд в ячейке ниже. В локальной
текущей директории ./ должны появиться:</p>
<ul>
<li>Папка train2014_5k с 5000 картинками</li>
<li>Файл train2014_5k.csv с 5000 промптами</li>
</ul>
<p>Данные парсятся корректным образом в уже реализованном классе
COCODataset.</p>
</div>
<div id="2431a4e8" class="cell code" data-execution_count="8"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:11:05.143390Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:11:05.142731Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:11:59.113031Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:11:59.111898Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:11:05.143349Z&quot;}"
id="2431a4e8" data-outputId="bfe08e7b-666c-46c4-b574-7dae6d164e20">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>wget https:<span class="op">//</span>storage.yandexcloud.net<span class="op">/</span>yandex<span class="op">-</span>research<span class="op">/</span>train2014_5k.tar.gz</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>tar <span class="op">-</span>xzf train2014_5k.tar.gz</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  pid, fd = os.forkpty()
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>--2024-12-05 22:11:06--  https://storage.yandexcloud.net/yandex-research/train2014_5k.tar.gz
Resolving storage.yandexcloud.net (storage.yandexcloud.net)... 213.180.193.243, 2a02:6b8::1d9
Connecting to storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 818380970 (780M) [application/x-tar]
Saving to: &#39;train2014_5k.tar.gz&#39;

train2014_5k.tar.gz 100%[===================&gt;] 780.47M  18.0MB/s    in 45s     

2024-12-05 22:11:52 (17.2 MB/s) - &#39;train2014_5k.tar.gz&#39; saved [818380970/818380970]

</code></pre>
</div>
</div>
<div id="bc010814" class="cell markdown" id="bc010814">
<p><strong>Замечание:</strong> для более быстрого дебаггинга можете
взять, например, 2500 картинок и прогнать на всей выборке только в самом
конце. 2500 картинок должно быть достаточно для понимания корректно ли
реализованы функции. Совсем для первичного дебаггинга можно взять еще
меньше картинок.</p>
</div>
<div id="e1ba81fb" class="cell code" data-execution_count="9"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:11:59.114952Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:11:59.114573Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:11:59.142019Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:11:59.141429Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:11:59.114911Z&quot;}"
id="e1ba81fb">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose(</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    [</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>        transforms.Resize(<span class="dv">512</span>),</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>        transforms.CenterCrop(<span class="dv">512</span>),</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>        <span class="kw">lambda</span> x: <span class="dv">2</span> <span class="op">*</span> x <span class="op">-</span> <span class="dv">1</span>,</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> COCODataset(<span class="st">&quot;.&quot;</span>,</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>    subset_name<span class="op">=</span><span class="st">&quot;train2014_5k&quot;</span>,</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>    transform<span class="op">=</span>transform,</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">len</span>(dataset) <span class="op">==</span> <span class="dv">5000</span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">8</span> <span class="co"># Рекоммендуемы размер батча на Colab</span></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>train_dataloader <span class="op">=</span> torch.utils.data.DataLoader(</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>    dataset<span class="op">=</span>dataset, shuffle<span class="op">=</span><span class="va">True</span>, batch_size<span class="op">=</span>batch_size, drop_last<span class="op">=</span><span class="va">True</span></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="cad222c2" class="cell code" data-execution_count="10"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:11:59.143126Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:11:59.142885Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:11:59.149020Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:11:59.148215Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:11:59.143103Z&quot;}"
id="cad222c2">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="at">@torch.no_grad</span>()</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prepare_batch(batch, pipe):</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Предобработка батча картинок и текстовых промптов.</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Маппим картинки в латентное пространство VAE.</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Извлекаем эмбеды промптов с помощью текстового энкодера.</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Params:</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Return:</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="co">        latents: torch.Tensor([B, 4, 64, 64], dtype=torch.float16)</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="co">        prompt_embeds: torch.Tensor([B, 77, D], dtype=torch.float16)</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Токенизируем промпты</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>    text_inputs <span class="op">=</span> pipe.tokenizer(</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>        batch[<span class="st">&#39;text&#39;</span>],</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>        padding<span class="op">=</span><span class="st">&quot;max_length&quot;</span>,</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span>pipe.tokenizer.model_max_length,</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>        truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>        return_tensors<span class="op">=</span><span class="st">&quot;pt&quot;</span>,</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Извлекаем эмбеды промптов с помощью текстового энкодера</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>    prompt_embeds <span class="op">=</span> pipe.text_encoder(text_inputs.input_ids.cuda())[<span class="dv">0</span>]</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Переводим картинки в латентное пространство VAE</span></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> batch[<span class="st">&#39;image&#39;</span>].to(<span class="st">&quot;cuda&quot;</span>, dtype<span class="op">=</span>torch.float16)</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>    latents <span class="op">=</span> pipe.vae.encode(image).latent_dist.sample()</span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>    latents <span class="op">=</span> latents <span class="op">*</span> pipe.vae.config.scaling_factor</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> latents, prompt_embeds</span></code></pre></div>
</div>
<div id="062a00a9" class="cell markdown" id="062a00a9">
<h3 id="подготовка-моделей-и-оптимизатора">Подготовка моделей и
оптимизатора</h3>
<p>Для начала создаем обучаемую модель: UNet инициализируемый весами
SD1.5. Вам нужно воспользоваться классом UNet2DConditionModel и
загрузить отдельно только UNet модель из SD1.5.</p>
<p>Отметим, что эта модель у нас будет храниться в полной точности FP32,
потому что обучение параметров в FP16 может приводить к нестабильностям
и низкому качеству.</p>
</div>
<div id="e2e73f1a" class="cell code" data-execution_count="11"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:11:59.150413Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:11:59.150088Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:12:00.843082Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:12:00.842091Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:11:59.150378Z&quot;}"
id="e2e73f1a">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>unet <span class="op">=</span> UNet2DConditionModel.from_pretrained(<span class="st">&quot;sd-legacy/stable-diffusion-v1-5&quot;</span>, subfolder<span class="op">=</span><span class="st">&quot;unet&quot;</span>).cuda()</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>unet.train()</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> unet.dtype <span class="op">==</span> torch.float32</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> unet.training</span></code></pre></div>
</div>
<div id="cd4f56cb" class="cell markdown" id="cd4f56cb">
<p>Для экономии памяти во время обучения будем учить не параметры самой
модели, а добавим в нее обучаемые LoRA адаптеры с малым числом
параметров.</p>
<p>LoRA представляет собой маленькую добавку к весам модели, где на одну
матрицу весов $W \in \mathbb{R}^{m{\times}n} $ обучаются две
низкоранговые матрицы <span
class="math inline"><em>W</em><sub><em>A</em></sub> ∈ ℝ<sup><em>k</em> × <em>n</em></sup></span>
и <span
class="math inline"><em>W</em><sub><em>B</em></sub> ∈ ℝ<sup><em>k</em> × <em>m</em></sup></span>,
где <span class="math inline"><em>k</em></span> - ранг матрицы сильно
меньше <span class="math inline"><em>m</em></span> и <span
class="math inline"><em>n</em></span>.</p>
<p>Тем самым, новая обученная матрица весов может быть представлена как
<span
class="math inline"><em>Ŵ</em> = <em>W</em> + <em>Δ</em><em>W</em> = <em>W</em> + <em>W</em><sub><em>B</em></sub><sup><em>T</em></sup><em>W</em><sub><em>A</em></sub></span>.<br />
Во время инференса <span class="math inline"><em>Δ</em><em>W</em></span>
можно вмержить в <span class="math inline"><em>W</em></span> и получить
итоговую модель. Также частая практика оставлять адаптеры как есть,
чтобы была возможность для одной базовой модели учить несколько
адаптеров под разные задачи и переключаться между ними по
необходимости.</p>
<p>Если не мержить адаптеры, то вычисления для линейного слоя происходят
как на картинке ниже.</p>
<p><img src=https://storage.yandexcloud.net/yandex-research/cvweek-cd-task-images/lora-idea.jpg width=300></p>
</div>
<div id="020bb504" class="cell code" data-execution_count="19"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:16:36.520575Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:16:36.520189Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:16:37.594695Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:16:37.593698Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:16:36.520542Z&quot;}"
id="020bb504">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Указываем к каким слоям модели мы будет добавлять адаптеры.</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>lora_modules <span class="op">=</span> [</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;to_q&quot;</span>, <span class="st">&quot;to_k&quot;</span>, <span class="st">&quot;to_v&quot;</span>, <span class="st">&quot;to_out.0&quot;</span>, <span class="st">&quot;proj_in&quot;</span>, <span class="st">&quot;proj_out&quot;</span>,</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;ff.net.0.proj&quot;</span>, <span class="st">&quot;ff.net.2&quot;</span>, <span class="st">&quot;conv1&quot;</span>, <span class="st">&quot;conv2&quot;</span>, <span class="st">&quot;conv_shortcut&quot;</span>,</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;downsamplers.0.conv&quot;</span>, <span class="st">&quot;upsamplers.0.conv&quot;</span>, <span class="st">&quot;time_emb_proj&quot;</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>lora_config <span class="op">=</span> LoraConfig(</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    r<span class="op">=</span><span class="dv">64</span>, <span class="co"># задает ранг у матриц A и B в LoRA.</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    target_modules<span class="op">=</span>lora_modules</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Создаем обертку исходной UNet модели с LoRA адаптерами, используя библиотеку PEFT</span></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>cm_unet <span class="op">=</span> get_peft_model(unet, lora_config, adapter_name<span class="op">=</span><span class="st">&quot;ct&quot;</span>)</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Включаем gradient checkpointing - важная техника для экономии памяти во время обучения</span></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>cm_unet.enable_gradient_checkpointing()</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Создаем оптимизатор</span></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.AdamW(cm_unet.parameters(), lr<span class="op">=</span><span class="fl">1e-4</span>)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Задаем лосс функцию для CM обжектива. В базовом варианте разумно взять L2</span></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a><span class="co"># По умолчанию, она уже выдает усредненное значение по всем размерностям</span></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>mse_loss <span class="op">=</span> torch.nn.functional.mse_loss</span></code></pre></div>
</div>
<div id="52bf9615" class="cell markdown" id="52bf9615">
<h2 id="задание-2-05-балла-сдается-в-контесте">Задание №2 (0.5 балла,
сдается в контесте)</h2>
<h4 id="реализация-шага-ddim">Реализация шага DDIM</h4>
<p>Шаг с помощью DDIM с <span
class="math inline"><strong>x</strong><sub><em>t</em></sub></span> на
<span class="math inline"><strong>x</strong><sub><em>s</em></sub></span>
можно сделать следующим образом:</p>
<p>$ \mathbf{x}<em>s = DDIM(\epsilon</em>\theta, \mathbf{x}<em>t, t, s)
= \alpha_s \cdot \left(\frac{\mathbf{x}<em>t - \sigma_t
\epsilon</em>\theta}{\alpha_t} \right) + \sigma_s \epsilon</em>\theta
$</p>
<p>Вам нужно реализовать эту формулу в уже готовом шаблоне ниже. Чтобы
корректно выполнить задание, вам нужно задать <span
class="math inline"><em>α</em><sub><em>t</em></sub></span> и <span
class="math inline"><em>σ</em><sub><em>t</em></sub></span> имея
<em>DDIMScheduler</em>. <strong>Обратите внимание на аттрибут
<em>scheduler.alphas_cumprod</em></strong>, который задает <span
class="math inline">$\bar\alpha_{t} = \prod^t_{i=1} (1-\beta_i)$</span>
в классической DDPM формулировке: <a
href="https://arxiv.org/pdf/2006.11239">Denoising Diffusion
Probabilistic Models</a>.</p>
</div>
<div id="229b66e7" class="cell code" data-execution_count="20"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:16:37.596611Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:16:37.596295Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:16:37.603060Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:16:37.602053Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:16:37.596584Z&quot;}"
id="229b66e7">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ddim_solver_step(model_output, x_t, t, s, scheduler):</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Шаг DDIM солвера для VP процесса зашумления и eps-prediction модели</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="co">    params:</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="co">        model_output: torch.Tensor[B, 4, 64, 64] - предсказание модели - шум eps</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="co">        x_t: torch.Tensor[B, 4, 64, 64] - сэмплы на шаге t</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="co">        t: torch.Tensor[B] - номер текущего шага</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="co">        s: torch.Tensor[B] - номер следующего шага</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a><span class="co">        scheduler: DDIMScheduler - расписание диффузионного процесса, чтобы получить alpha и sigma</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>    alphas <span class="op">=</span> scheduler.alphas_cumprod <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>    sigmas <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> scheduler.alphas_cumprod) <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>    sigmas_s <span class="op">=</span> extract_into_tensor(sigmas, s, x_t.shape)</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>    alphas_s <span class="op">=</span> extract_into_tensor(alphas, s, x_t.shape)</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>    sigmas_t <span class="op">=</span> extract_into_tensor(sigmas, t, x_t.shape)</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>    alphas_t <span class="op">=</span> extract_into_tensor(alphas, t, x_t.shape)</span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>    alphas_s[s <span class="op">==</span> <span class="dv">0</span>] <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>    sigmas_s[s <span class="op">==</span> <span class="dv">0</span>] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>    alphas_t[t <span class="op">==</span> <span class="dv">0</span>] <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>    sigmas_t[t <span class="op">==</span> <span class="dv">0</span>] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>    x_0 <span class="op">=</span> (x_t <span class="op">-</span> sigmas_t <span class="op">*</span> model_output) <span class="op">/</span> alphas_t</span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>    x_s <span class="op">=</span> alphas_s <span class="op">*</span> x_0 <span class="op">+</span> sigmas_s <span class="op">*</span> model_output</span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_s</span></code></pre></div>
</div>
<div id="c4013fc3" class="cell markdown" id="c4013fc3">
<h4 id="реализация-процесса-зашумления-q-sample">Реализация процесса
зашумления (q sample)</h4>
<p>Аналогично, нам нужен процесс зашумления <span
class="math inline"><em>q</em>(<strong>x</strong><sub><em>t</em></sub>|<strong>x</strong><sub>0</sub>) = <em>N</em>(<strong>x</strong><sub><em>t</em></sub>|<em>α</em><sub><em>t</em></sub><strong>x</strong><sub>0</sub>,<em>σ</em><sub><em>t</em></sub><sup>2</sup><em>I</em>)</span></p>
<p><span
class="math inline"><strong>x</strong><sub><em>t</em></sub> = <em>α</em><sub><em>t</em></sub><strong>x</strong><sub>0</sub> + <em>σ</em><sub><em>t</em></sub><em>ϵ</em></span>,
где <span
class="math inline"><em>ϵ</em> ∼ <em>N</em>(0,<em>I</em>)</span></p>
</div>
<div id="9fdb169c" class="cell code" data-execution_count="21"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:16:38.200686Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:16:38.199929Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:16:38.205945Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:16:38.204964Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:16:38.200651Z&quot;}"
id="9fdb169c">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> q_sample(x, t, scheduler, noise<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    alphas <span class="op">=</span> scheduler.alphas_cumprod <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>    sigmas <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> scheduler.alphas_cumprod) <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> noise <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>        noise <span class="op">=</span> torch.randn_like(x)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>    sigmas_t <span class="op">=</span> extract_into_tensor(sigmas, t, x.shape)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    alphas_t <span class="op">=</span> extract_into_tensor(alphas, t, x.shape)</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>    alphas_t[t <span class="op">==</span> <span class="dv">0</span>] <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>    sigmas_t[t <span class="op">==</span> <span class="dv">0</span>] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>    x_t <span class="op">=</span> alphas_t <span class="op">*</span> x <span class="op">+</span> sigmas_t <span class="op">*</span> noise</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_t</span></code></pre></div>
</div>
<div id="21c5893c" class="cell markdown" id="21c5893c">
<h1 id="consistency-training">Consistency Training</h1>
<p>Обучение консистенси моделей без учителя называется Consistency
Training (CT). В таком случае CM можно рассматривать как отдельный вид
генеративных моделей. Давайте начнем именно с этого подхода и обучим
нашу первую консистенси модель на базе SD1.5.</p>
</div>
<div id="6d5743b1" class="cell markdown" id="6d5743b1">
<h2 id="задание-3">Задание №3</h2>
<h4 id="задание-31-05-балла-сдается-в-контесте">Задание №3.1 (0.5 балла,
сдается в контесте)</h4>
<p>В консиcтенси дистилляции модель учителя используется для получения
второй точки на траектории ODE. Можем ли мы попробовать оценить соседнюю
точку аналитически?</p>
<p>Вам предлагается вывести это самим, используя формулу DDIM шага выше
и вспомнив, как мы оцениваем скор функции в denoising score
matching-e:</p>
<p><span
class="math inline"><em>ϵ</em><sub><em>θ</em></sub>(<em>x</em><sub><em>t</em></sub>,<em>t</em>) =  − <em>σ</em><sub><em>t</em></sub><em>s</em><sub><em>θ</em></sub>(<em>x</em><sub><em>t</em></sub>,<em>t</em>)</span></p>
<p><span
class="math inline"><em>s</em><sub><em>θ</em></sub>(<em>x</em><sub><em>t</em></sub>,<em>t</em>) ≈ ∇<sub><em>x</em><sub><em>t</em></sub></sub>log <em>q</em>(<em>x</em><sub><em>t</em></sub>) = 𝔼<sub><strong>x</strong> ∼ <em>p</em><sub><em>d</em><em>a</em><em>t</em><em>a</em></sub></sub>[∇<sub><strong>x</strong><sub><em>t</em></sub></sub>log<em>q</em>(<strong>x</strong><sub><em>t</em></sub>|<strong>x</strong>)|<strong>x</strong><sub><em>t</em></sub>] ≈ ∇<sub><strong>x</strong><sub><em>t</em></sub></sub>log <em>q</em>(<strong>x</strong><sub><em>t</em></sub>|<strong>x</strong>)</span></p>
<hr />
<p>$ \mathbf{x}<em>s = DDIM(\epsilon</em>\theta, \mathbf{x}<em>t, t, s)
= \alpha_s \cdot \left(\frac{\mathbf{x}<em>t - \sigma_t
\epsilon</em>\theta}{\alpha_t} \right) + \sigma_s \epsilon</em>\theta
$</p>
<p>$ \mathbf{x}<em>t-\alpha_t x_0 = \sigma_t \epsilon</em>\theta $</p>
<p>$ \mathbf{x}<em>s = \alpha_s \cdot x_0+ \sigma_s \epsilon</em>\theta
= \alpha_s \cdot x_0+ (\mathbf{x}_t-\alpha_t x_0)
\frac{\sigma_s}{\sigma_t} $</p>
<p><span class="math inline">$x_s = \alpha_s \cdot x_0+
(\mathbf{x}_t-\alpha_t x_0) \frac{\sigma_s}{\sigma_t}$</span></p>
<hr />
<p>Если возникнут трудности, можно обратиться к оригинальной <a
href="https://arxiv.org/pdf/2303.01469">статье</a>.</p>
</div>
<div id="6a321f6b" class="cell markdown" id="6a321f6b">
<p>Теперь реализуем то, что у вас получилось в функции ниже.</p>
</div>
<div id="ff58cba2" class="cell code" data-execution_count="22"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:16:40.543134Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:16:40.542371Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:16:40.548892Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:16:40.547891Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:16:40.543098Z&quot;}"
id="ff58cba2">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_xs_from_xt_naive(</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>    x_0, x_t, t, s, <span class="co"># Не все эти аргументы могут быть вам нужны</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    scheduler,</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    noise<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>kwargs</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Получение точки x_s в CT режиме, т.е., аналитически.</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x_t <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>        alphas <span class="op">=</span> scheduler.alphas_cumprod <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>        sigmas <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> scheduler.alphas_cumprod) <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>        sigmas_t <span class="op">=</span> extract_into_tensor(sigmas, t, x_t.shape)</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>        alphas_t <span class="op">=</span> extract_into_tensor(alphas, t, x_t.shape)</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>        alphas_t[t <span class="op">==</span> <span class="dv">0</span>] <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>        sigmas_t[t <span class="op">==</span> <span class="dv">0</span>] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>        noise <span class="op">=</span> (x_t <span class="op">-</span> alphas_t <span class="op">*</span> x_0) <span class="op">/</span> sigmas_t</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>    x_s <span class="op">=</span> q_sample(x_0, s, scheduler, noise)</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_s</span></code></pre></div>
</div>
<div id="a967d0f5" class="cell markdown" id="a967d0f5">
<h4 id="задание-32">Задание №3.2</h4>
<p>Ниже предстален шаблон функции, которая считает лосс для консистенси
моделей. Вам нужно правильно заполнить пропуски, чтобы получилась
корректная функция.</p>
</div>
<div id="675acdd5" class="cell code" data-execution_count="23"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:16:41.807025Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:16:41.806320Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:16:41.814462Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:16:41.813635Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:16:41.806989Z&quot;}"
id="675acdd5">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cm_loss_template(</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    latents, prompt_embeds, <span class="co"># батч латентов и текстовых эмбедов</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    unet, scheduler,</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Функции, которые будем постепенно менять из задания к заданию</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    loss_fn: <span class="bu">callable</span>,</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    get_boundary_timesteps: <span class="bu">callable</span>,</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>    get_xs_from_xt: <span class="bu">callable</span>,</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>    num_timesteps<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>    step_size<span class="op">=</span><span class="dv">20</span>, <span class="co"># Указываем с каким интервалом берем шаги s и t.</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Сэмплируем случайные шаги t для каждого элемента батча t ~ U[step_size-1, 999]</span></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> num_timesteps <span class="op">==</span> <span class="dv">1000</span></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>    num_intervals <span class="op">=</span> num_timesteps <span class="op">//</span> step_size</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>    index <span class="op">=</span> torch.randint(<span class="dv">1</span>, num_intervals, (<span class="bu">len</span>(latents),), device<span class="op">=</span>latents.device).<span class="bu">long</span>() <span class="co"># [1, num_intervals]</span></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> step_size <span class="op">*</span> index <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> torch.clamp(t <span class="op">-</span> step_size, <span class="bu">min</span><span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>    boundary_timesteps <span class="op">=</span> get_boundary_timesteps(</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>        s, num_timesteps<span class="op">=</span>num_timesteps</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Сэмплируем x_t</span></span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a>    noise <span class="op">=</span> torch.randn_like(latents)</span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a>    x_t <span class="op">=</span> q_sample(latents, t, scheduler, noise)</span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.amp.autocast(<span class="st">&quot;cuda&quot;</span>, torch.float16):</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a>        noise_pred <span class="op">=</span> unet(x_t.<span class="bu">float</span>(), t,</span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a>            encoder_hidden_states<span class="op">=</span>prompt_embeds.<span class="bu">float</span>(),</span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>        ).sample</span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Получаем оценку в граничной точке для x_t</span></span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a>    boundary_pred <span class="op">=</span> ddim_solver_step(noise_pred, x_t, t, boundary_timesteps, scheduler)</span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Получаем сэмпл x_s из x_t</span></span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a>    x_s <span class="op">=</span> get_xs_from_xt(</span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a>        latents, x_t, t, s,</span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a>        scheduler,</span>
<span id="cb39-40"><a href="#cb39-40" aria-hidden="true" tabindex="-1"></a>        prompt_embeds<span class="op">=</span>prompt_embeds,</span>
<span id="cb39-41"><a href="#cb39-41" aria-hidden="true" tabindex="-1"></a>        noise<span class="op">=</span>noise,</span>
<span id="cb39-42"><a href="#cb39-42" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb39-43"><a href="#cb39-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-44"><a href="#cb39-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Предсказание &quot;таргет моделью&quot;</span></span>
<span id="cb39-45"><a href="#cb39-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad(), torch.amp.autocast(<span class="st">&quot;cuda&quot;</span>, torch.float16):</span>
<span id="cb39-46"><a href="#cb39-46" aria-hidden="true" tabindex="-1"></a>        target_noise_pred <span class="op">=</span> unet(x_s, s, encoder_hidden_states<span class="op">=</span>prompt_embeds).sample</span>
<span id="cb39-47"><a href="#cb39-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-48"><a href="#cb39-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Получаем оценку в граничной точке для x_s</span></span>
<span id="cb39-49"><a href="#cb39-49" aria-hidden="true" tabindex="-1"></a>    boundary_target <span class="op">=</span> ddim_solver_step(target_noise_pred, x_s, s, boundary_timesteps, scheduler)</span>
<span id="cb39-50"><a href="#cb39-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-51"><a href="#cb39-51" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(boundary_pred, boundary_target)</span>
<span id="cb39-52"><a href="#cb39-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss</span></code></pre></div>
</div>
<div id="63c0c60d" class="cell code" data-execution_count="24"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:16:42.425668Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:16:42.425050Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:16:42.430127Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:16:42.429334Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:16:42.425635Z&quot;}"
id="63c0c60d">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> functools</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_zero_boundary_timesteps(t, <span class="op">**</span>kwargs):</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Определяем шаги где будут срабатывать граничные условия.</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Для классических СM это t=0.</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.zeros_like(t)</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>ct_loss <span class="op">=</span> functools.partial(</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>    cm_loss_template,</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>    loss_fn<span class="op">=</span>mse_loss,</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>    get_boundary_timesteps<span class="op">=</span>get_zero_boundary_timesteps,</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>    get_xs_from_xt<span class="op">=</span>get_xs_from_xt_naive</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> cm_unet.active_adapter <span class="op">==</span> <span class="st">&#39;ct&#39;</span></span></code></pre></div>
</div>
<div id="5c526cc4" class="cell markdown" id="5c526cc4">
<h2 id="задание-4">Задание №4</h2>
<h3 id="эффективное-обучение">Эффективное обучение</h3>
<p>Данное задание рассчитано на успешное выполнение на colab с
бесплатной Tesla T4 c 15GB VRAM. Однако учить даже относительно
небольшие T2I модели масштаба SD1.5 уже на коллабе в лоб
проблематично.</p>
<p>Для этого нам нужно применить ряд инженерных техник, чтобы уместиться
в данный бюджет и учиться за разумное время.</p>
<p><strong>Список техник</strong></p>
<p>1) Включить gradient checkpointing для обучемой модели 2) Добавить
LoRA (Low Rank Adapters) адаптеры, чтобы учить не все веса, а только 10%
добавочных весов 3) Использовать gradient accumulation, чтобы делать
итерацию обучения по бОльшему батчу, чем влезает по памяти 4) Добавить
mixed precision FP16/FP32 обучение модели для скорости. Обычно еще и
память экономится, но в случае LoRA обучения + gradient checkpointing на
память сильно влиять не должно, но зато станет быстрее. 5) Мульти-GPU
обучение - распределение вычислений по нескольким GPU.</p>
<p>1-2) Мы уже применили за вас выше</p>
<p>3-4) Предстоит реализовать вам самим в соотвествующей секции ниже</p>
<p>5 ) Недоступно, так как работаем на одной карточке</p>
</div>
<div id="81dbf465" class="cell markdown" id="81dbf465">
<h3 id="обучающий-цикл">Обучающий цикл</h3>
<p>Вам дан код обучения модель в полной точности (FP32) c батчом 8. К
сожалению, на Tesla T4 мы не влезем по памяти. Поэтому в ячейке ниже вам
нужно модифицировать цикл, чтобы он работал в mixed precision FP16 и
добавить gradient accumulation.</p>
<p>Про реализацию mixed-precision в pytorch можно перейти по ссылке: <a
href="https://pytorch.org/docs/stable/notes/amp_examples.html#typical-mixed-precision-training">Mixed-precision
обучение</a></p>
<p><strong>Обратите внимание</strong>: вам еще нужно добавить одну
строчку кода в <em>cm_loss_template</em> в соответствующем
плейсхолдере.</p>
<p><strong>Замечание:</strong> В начале обучения значения лосса должны
быть в окрестности 0.0007-0.001. Ничего страшного, что лосс не падает,
для CM это нормально. В конце обучения лосс может доходить до
0.005-0.01</p>
</div>
<div id="QoidXNBgZgkY" class="cell code" data-execution_count="25"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:16:45.553183Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:16:45.552340Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T22:16:45.558911Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T22:16:45.557983Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:16:45.553148Z&quot;}"
id="QoidXNBgZgkY">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_loop(model, pipe, train_dataloader, optimizer, loss_fn, num_grad_accum<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>    torch.cuda.empty_cache()</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>    scaler <span class="op">=</span> torch.amp.GradScaler()</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad(set_to_none<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(train_dataloader)):</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>        latents, prompt_embeds <span class="op">=</span> prepare_batch(batch, pipe)</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.amp.autocast(device_type<span class="op">=</span><span class="st">&#39;cuda&#39;</span>, dtype<span class="op">=</span>torch.float16):</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(latents, prompt_embeds, model, pipe.scheduler)</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Обновляем параметры</span></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>        scaler.scale(loss).backward()</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (i <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> num_grad_accum <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>            scaler.step(optimizer)</span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad(set_to_none<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>            scaler.update()</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>detach()<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
</div>
<div id="79a5f675" class="cell code" data-execution_count="26"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000,&quot;referenced_widgets&quot;:[&quot;cbb955192d354867afea426ad18f9436&quot;,&quot;f5182b2111c24558ac4a76665a3a8b32&quot;,&quot;052038f364154b47b6cb3f0519c05e9a&quot;,&quot;bd6b8a9a1e86499e8e0eb092ff8ca069&quot;,&quot;b5ccf46ea13b4765ac9d143069bcfc29&quot;,&quot;82b5f7c6be02472485ddf4af79841844&quot;,&quot;775de7ca04b54a4eb28afacb4244a269&quot;,&quot;c01afa32b91d46328d2525150dd077a6&quot;,&quot;a6c70a5b1a4549c4981365867258f909&quot;,&quot;be2d186583e24c378adf97c6aabdca6b&quot;,&quot;fff24827bfbc47f5a3d53d85a8168c77&quot;]}"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T22:16:55.484166Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T22:16:55.483816Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T23:13:31.249613Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T23:13:31.248690Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T22:16:55.484136Z&quot;}"
id="79a5f675" data-outputId="04197c8a-c72b-4396-a0d9-4e1065745279">
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>num_grad_accum <span class="op">=</span> <span class="dv">2</span> <span class="co"># обновляем параметры каждые 2 шага</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>train_loop(cm_unet, pipe, train_dataloader, optimizer, ct_loss, num_grad_accum)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb43"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;96df05f68eaa484885741078f3a9b69a&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast(&#39;cpu&#39;, args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Loss: 0.0022781677544116974
Loss: 0.0011679697781801224
Loss: 0.0023438807111233473
Loss: 0.000953603652305901
Loss: 0.001677110674791038
Loss: 0.0010915936436504126
Loss: 0.000910559669137001
Loss: 0.0009111532126553357
Loss: 0.002004441572353244
Loss: 0.0009868184570223093
Loss: 0.003151088487356901
Loss: 0.00099285040050745
Loss: 0.002053150674328208
Loss: 0.0008401955128647387
Loss: 0.0009563780622556806
Loss: 0.00045950099593028426
Loss: 0.0008209405350498855
Loss: 0.0008300041081383824
Loss: 0.0021012015640735626
Loss: 0.0009169256081804633
Loss: 0.002782720373943448
Loss: 0.0011727181263267994
Loss: 0.001393612939864397
Loss: 0.0012092243414372206
Loss: 0.001026206067763269
Loss: 0.0006412224611267447
Loss: 0.0018491805531084538
Loss: 0.0012093487894162536
Loss: 0.0011157921981066465
Loss: 0.0013276553945615888
Loss: 0.0012365230359137058
Loss: 0.0013510615099221468
Loss: 0.0022465335205197334
Loss: 0.0018607020610943437
Loss: 0.0014639453729614615
Loss: 0.0011607748456299305
Loss: 0.0014201804297044873
Loss: 0.0022982032969594
Loss: 0.0015474185347557068
Loss: 0.007767189759761095
Loss: 0.0008130627102218568
Loss: 0.0013351477682590485
Loss: 0.0013357731513679028
Loss: 0.001050683669745922
Loss: 0.0009811242343857884
Loss: 0.006983957253396511
Loss: 0.0009493280667811632
Loss: 0.0010901994537562132
Loss: 0.0008690673275850713
Loss: 0.0016143169486895204
Loss: 0.0014527416788041592
Loss: 0.002639263402670622
Loss: 0.001133794547058642
Loss: 0.0014472923940047622
Loss: 0.0016158445505425334
Loss: 0.0025913924910128117
Loss: 0.0015170939732342958
Loss: 0.0014293680433183908
Loss: 0.002153311390429735
Loss: 0.0011776558822020888
Loss: 0.0029232846572995186
Loss: 0.0023300698958337307
Loss: 0.003258313750848174
Loss: 0.001105365576222539
Loss: 0.0016713960794731975
Loss: 0.004212338477373123
Loss: 0.0027017700485885143
Loss: 0.001705409842543304
Loss: 0.0020810356363654137
Loss: 0.0022718789987266064
Loss: 0.001341652125120163
Loss: 0.001434968551620841
Loss: 0.0018412251956760883
Loss: 0.0024967333301901817
Loss: 0.0034638638608157635
Loss: 0.003147686365991831
Loss: 0.0015804339200258255
Loss: 0.001980098430067301
Loss: 0.0015622817445546389
Loss: 0.002326956717297435
Loss: 0.0014799872878938913
Loss: 0.0019049335969612002
Loss: 0.003984986338764429
Loss: 0.00474837189540267
Loss: 0.0039992742240428925
Loss: 0.007991809397935867
Loss: 0.002352304756641388
Loss: 0.0015329413581639528
Loss: 0.002071565017104149
Loss: 0.003558412194252014
Loss: 0.0032061589881777763
Loss: 0.01026000827550888
Loss: 0.005982787348330021
Loss: 0.00868772342801094
Loss: 0.006932251155376434
Loss: 0.0031156728509813547
Loss: 0.00477526756003499
Loss: 0.003787684254348278
Loss: 0.007613875437527895
Loss: 0.004454814828932285
Loss: 0.0034733563661575317
Loss: 0.01142907701432705
Loss: 0.0064552705734968185
Loss: 0.0029377650935202837
Loss: 0.006484143435955048
Loss: 0.003841500263661146
Loss: 0.003544011153280735
Loss: 0.003570087719708681
Loss: 0.01308814063668251
Loss: 0.002090544905513525
Loss: 0.0014125456800684333
Loss: 0.004333184100687504
Loss: 0.007227672263979912
Loss: 0.0041045695543289185
Loss: 0.0027176833245903254
Loss: 0.0009418053668923676
Loss: 0.0015533901751041412
Loss: 0.003460815642029047
Loss: 0.003956059459596872
Loss: 0.0025356393307447433
Loss: 0.0031893353443592787
Loss: 0.004012965131551027
Loss: 0.0017170755891129375
Loss: 0.004164036363363266
Loss: 0.0022044829092919827
Loss: 0.0027428476605564356
Loss: 0.004217690788209438
Loss: 0.0023644808679819107
Loss: 0.004229982383549213
Loss: 0.004394559655338526
Loss: 0.0017413257155567408
Loss: 0.003953259438276291
Loss: 0.0015130784595385194
Loss: 0.0013983866665512323
Loss: 0.0014895079657435417
Loss: 0.001633558771573007
Loss: 0.0037301017437130213
Loss: 0.0013329273788258433
Loss: 0.0015017814002931118
Loss: 0.002117686904966831
Loss: 0.0024963081814348698
Loss: 0.0030897636897861958
Loss: 0.0018761925166472793
Loss: 0.0019400857854634523
Loss: 0.0017737738089635968
Loss: 0.0020140635315328836
Loss: 0.001809237408451736
Loss: 0.0026273648254573345
Loss: 0.0013435857836157084
Loss: 0.0017892919713631272
Loss: 0.0018303592223674059
Loss: 0.0011942638084292412
Loss: 0.0023978797253221273
Loss: 0.003366178832948208
Loss: 0.0011617876589298248
Loss: 0.002006364054977894
Loss: 0.001818875432945788
Loss: 0.00328512629494071
Loss: 0.0010669559706002474
Loss: 0.0011161380680277944
Loss: 0.0012312454637140036
Loss: 0.001969359815120697
Loss: 0.0012066909112036228
Loss: 0.0021014141384512186
Loss: 0.0018843389116227627
Loss: 0.0011039399541914463
Loss: 0.0024951579980552197
Loss: 0.0014481553807854652
Loss: 0.0016022282652556896
Loss: 0.001743054250255227
Loss: 0.0015202981885522604
Loss: 0.0017453168984502554
Loss: 0.0026617932599037886
Loss: 0.0013988795690238476
Loss: 0.0014684420311823487
Loss: 0.0023235525004565716
Loss: 0.0017310562543570995
Loss: 0.001468857517465949
Loss: 0.0020891630556434393
Loss: 0.003266073763370514
Loss: 0.001623069983907044
Loss: 0.000987525563687086
Loss: 0.0009413748048245907
Loss: 0.0009026963962242007
Loss: 0.002624022774398327
Loss: 0.0012590008554980159
Loss: 0.0010950937867164612
Loss: 0.002013332676142454
Loss: 0.0017361848149448633
Loss: 0.001694416394457221
Loss: 0.0029595191590487957
Loss: 0.0036548839416354895
Loss: 0.0019976673647761345
Loss: 0.00165869714692235
Loss: 0.0019224131247028708
Loss: 0.001862377393990755
Loss: 0.0009275008924305439
Loss: 0.004402389749884605
Loss: 0.002093038521707058
Loss: 0.0021348544396460056
Loss: 0.0012731426395475864
Loss: 0.0012809807667508721
Loss: 0.001564695849083364
Loss: 0.0012642620131373405
Loss: 0.001669371034950018
Loss: 0.0013895516749471426
Loss: 0.0008150670910254121
Loss: 0.001613754779100418
Loss: 0.0022808981593698263
Loss: 0.0015391947235912085
Loss: 0.001524660037830472
Loss: 0.0012452106457203627
Loss: 0.0018664872040972114
Loss: 0.002647451125085354
Loss: 0.0015039041172713041
Loss: 0.001786320935934782
Loss: 0.0034916712902486324
Loss: 0.0017117595998570323
Loss: 0.0023433102760463953
Loss: 0.002754224231466651
Loss: 0.0018259785138070583
Loss: 0.001376181491650641
Loss: 0.0010549909202381968
Loss: 0.002521618502214551
Loss: 0.0027318857610225677
Loss: 0.0014179571298882365
Loss: 0.002372839953750372
Loss: 0.00326172704808414
Loss: 0.0025858324952423573
Loss: 0.0027465741150081158
Loss: 0.0014526128070428967
Loss: 0.001570684602484107
Loss: 0.000812202284578234
Loss: 0.001538013108074665
Loss: 0.001735208323225379
Loss: 0.0016574931796640158
Loss: 0.004246349446475506
Loss: 0.002776393434032798
Loss: 0.0012031090445816517
Loss: 0.0020486293360590935
Loss: 0.0013849262613803148
Loss: 0.00128350465092808
Loss: 0.0020831627771258354
Loss: 0.0030530805233865976
Loss: 0.004335962235927582
Loss: 0.002244234085083008
Loss: 0.0016743260202929378
Loss: 0.0015211920253932476
Loss: 0.0014524688012897968
Loss: 0.001897689187899232
Loss: 0.0010698680998757482
Loss: 0.0015540277818217874
Loss: 0.0020780139602720737
Loss: 0.0026580262929201126
Loss: 0.003063273150473833
Loss: 0.001951688900589943
Loss: 0.0034781370777636766
Loss: 0.001965009607374668
Loss: 0.002036778721958399
Loss: 0.0036846862640231848
Loss: 0.004076095297932625
Loss: 0.0020292685367166996
Loss: 0.00243161479011178
Loss: 0.0019561059307307005
Loss: 0.004173914901912212
Loss: 0.0031852517277002335
Loss: 0.0016131449956446886
Loss: 0.001719099935144186
Loss: 0.0032021955121308565
Loss: 0.003241435158997774
Loss: 0.0016982348170131445
Loss: 0.002208008896559477
Loss: 0.0018120019230991602
Loss: 0.0017466738354414701
Loss: 0.0011329534463584423
Loss: 0.0012427140027284622
Loss: 0.0022931466810405254
Loss: 0.0017986599123105407
Loss: 0.001322974800132215
Loss: 0.001438479172065854
Loss: 0.00447950791567564
Loss: 0.0017178812995553017
Loss: 0.001822028774768114
Loss: 0.0024918774142861366
Loss: 0.0012512868270277977
Loss: 0.001783094136044383
Loss: 0.002092505805194378
Loss: 0.001574898837134242
Loss: 0.0020278450101614
Loss: 0.002151088323444128
Loss: 0.0020691233221441507
Loss: 0.0015125811332836747
Loss: 0.0035968576557934284
Loss: 0.005283963400870562
Loss: 0.0021014660596847534
Loss: 0.0020249909721314907
Loss: 0.003639251459389925
Loss: 0.0030473112128674984
Loss: 0.003809656947851181
Loss: 0.0027291972655802965
Loss: 0.0017135303933173418
Loss: 0.0015603407518938184
Loss: 0.0021106183994561434
Loss: 0.004137415438890457
Loss: 0.001966095296666026
Loss: 0.003710083896294236
Loss: 0.0018804460996761918
Loss: 0.003687458811327815
Loss: 0.0020487699657678604
Loss: 0.0023132958449423313
Loss: 0.001741729094646871
Loss: 0.0017396941548213363
Loss: 0.0018291760934516788
Loss: 0.0029323906637728214
Loss: 0.0019390316447243094
Loss: 0.0012334608472883701
Loss: 0.0025141891092061996
Loss: 0.0023556349333375692
Loss: 0.001436455175280571
Loss: 0.0023653008975088596
Loss: 0.002836400642991066
Loss: 0.002931733848527074
Loss: 0.0029354484286159277
Loss: 0.0032289959490299225
Loss: 0.005605281330645084
Loss: 0.0020827753469347954
Loss: 0.0023455508053302765
Loss: 0.002759699709713459
Loss: 0.0016118116909638047
Loss: 0.0016738222911953926
Loss: 0.0033822208642959595
Loss: 0.002991969231516123
Loss: 0.0022638191003352404
Loss: 0.0018681727815419436
Loss: 0.0017544252332299948
Loss: 0.0020567523315548897
Loss: 0.00318186916410923
Loss: 0.0036470452323555946
Loss: 0.001656621228903532
Loss: 0.0032997960224747658
Loss: 0.003894637804478407
Loss: 0.0038327770307660103
Loss: 0.0019352227682247758
Loss: 0.003922775387763977
Loss: 0.0031916380394250154
Loss: 0.004977194592356682
Loss: 0.001487140660174191
Loss: 0.0022151730954647064
Loss: 0.004813055042177439
Loss: 0.0017231241799890995
Loss: 0.002834160579368472
Loss: 0.0027985181659460068
Loss: 0.0028014727868139744
Loss: 0.0017462251707911491
Loss: 0.002822352573275566
Loss: 0.004054970107972622
Loss: 0.006919186096638441
Loss: 0.002644839696586132
Loss: 0.0014844972174614668
Loss: 0.0030527161434292793
Loss: 0.002005631336942315
Loss: 0.0028845658525824547
Loss: 0.004119782242923975
Loss: 0.0033455491065979004
Loss: 0.0031907432712614536
Loss: 0.0024629784747958183
Loss: 0.0028925109654664993
Loss: 0.0036719348281621933
Loss: 0.002285544527694583
Loss: 0.0023107104934751987
Loss: 0.003402067581191659
Loss: 0.0018983487971127033
Loss: 0.0038693544920533895
Loss: 0.0024660334456712008
Loss: 0.003098710672929883
Loss: 0.0018494846299290657
Loss: 0.0009853941155597568
Loss: 0.0016679768450558186
Loss: 0.002370786853134632
Loss: 0.0027458532713353634
Loss: 0.004541181493550539
Loss: 0.0021470594219863415
Loss: 0.00319032184779644
Loss: 0.002299410756677389
Loss: 0.002365079475566745
Loss: 0.0033503002487123013
Loss: 0.0037530025001615286
Loss: 0.003593804780393839
Loss: 0.00113542506005615
Loss: 0.001624399097636342
Loss: 0.0016254459042102098
Loss: 0.0018894132226705551
Loss: 0.0013066728133708239
Loss: 0.0022473367862403393
Loss: 0.003862854791805148
Loss: 0.0017403968377038836
Loss: 0.002705787308514118
Loss: 0.0023874137550592422
Loss: 0.0017269811360165477
Loss: 0.0013464461080729961
Loss: 0.002418878488242626
Loss: 0.0012231961591169238
Loss: 0.0016314839012920856
Loss: 0.0027408567257225513
Loss: 0.0045474013313651085
Loss: 0.0026142157148569822
Loss: 0.0021087287459522486
Loss: 0.002085581421852112
Loss: 0.0028633440379053354
Loss: 0.002544607501477003
Loss: 0.002030304865911603
Loss: 0.002076044213026762
Loss: 0.0023848344571888447
Loss: 0.0020022063981741667
Loss: 0.002177625661715865
Loss: 0.0024525225162506104
Loss: 0.0016742884181439877
Loss: 0.002141522243618965
Loss: 0.002309638075530529
Loss: 0.0032088961452245712
Loss: 0.0031281900592148304
Loss: 0.0010383457411080599
Loss: 0.0037926845252513885
Loss: 0.0014819734496995807
Loss: 0.0014133163494989276
Loss: 0.0017947530141100287
Loss: 0.002719950396567583
Loss: 0.003730776719748974
Loss: 0.0030298633500933647
Loss: 0.0016692545032128692
Loss: 0.0015638405457139015
Loss: 0.0043801493011415005
Loss: 0.0017639538273215294
Loss: 0.006589721422642469
Loss: 0.003786276327446103
Loss: 0.004578809253871441
Loss: 0.003301402321085334
Loss: 0.0024550207890570164
Loss: 0.0054738521575927734
Loss: 0.0011223697802051902
Loss: 0.0022020984906703234
Loss: 0.001672550686635077
Loss: 0.002984085353091359
Loss: 0.0030884549487382174
Loss: 0.002250347286462784
Loss: 0.0022354316897690296
Loss: 0.002076053526252508
Loss: 0.001871609827503562
Loss: 0.003071231534704566
Loss: 0.0033838932868093252
Loss: 0.0022185933776199818
Loss: 0.0037120403721928596
Loss: 0.004256531596183777
Loss: 0.0018419595435261726
Loss: 0.0026251052040606737
Loss: 0.002421436831355095
Loss: 0.0028987685218453407
Loss: 0.0017597777768969536
Loss: 0.0019887348171323538
Loss: 0.003340798197314143
Loss: 0.0024389249738305807
Loss: 0.004628010559827089
Loss: 0.0028646718710660934
Loss: 0.0041769505478441715
Loss: 0.0036041433922946453
Loss: 0.0023358985781669617
Loss: 0.002128248568624258
Loss: 0.0016137172933667898
Loss: 0.0016880021430552006
Loss: 0.0019199890084564686
Loss: 0.004780517891049385
Loss: 0.0019973041489720345
Loss: 0.0021768256556242704
Loss: 0.0015844102017581463
Loss: 0.0028134938329458237
Loss: 0.002657124074175954
Loss: 0.0024043391458690166
Loss: 0.0032049198634922504
Loss: 0.0018231740687042475
Loss: 0.003543571103364229
Loss: 0.004333165008574724
Loss: 0.0020253683906048536
Loss: 0.003187969559803605
Loss: 0.0020080639515072107
Loss: 0.0013438966125249863
Loss: 0.002336197067052126
Loss: 0.0019490884151309729
Loss: 0.0020130909979343414
Loss: 0.002938351593911648
Loss: 0.0012254978064447641
Loss: 0.004936296492815018
Loss: 0.0019522149814292789
Loss: 0.003178057726472616
Loss: 0.0018027981277555227
Loss: 0.0031034003477543592
Loss: 0.0028177027124911547
Loss: 0.0015250571304932237
Loss: 0.0030964824836701155
Loss: 0.002694682916626334
Loss: 0.0029955138452351093
Loss: 0.0036575656849890947
Loss: 0.0032555782236158848
Loss: 0.0022276281379163265
Loss: 0.0020970692858099937
Loss: 0.0015944456681609154
Loss: 0.003275148803368211
Loss: 0.0013962191296741366
Loss: 0.0028628967702388763
Loss: 0.001626084209419787
Loss: 0.0014718992169946432
Loss: 0.0028345538303256035
Loss: 0.0028914110735058784
Loss: 0.002967166481539607
Loss: 0.0022019976750016212
Loss: 0.0026096024084836245
Loss: 0.0036134780384600163
Loss: 0.003273135982453823
Loss: 0.001129096606746316
Loss: 0.0027543301694095135
Loss: 0.003756988327950239
Loss: 0.0032097268849611282
Loss: 0.0036455844528973103
Loss: 0.003480475628748536
Loss: 0.0021889712661504745
Loss: 0.0034214791376143694
Loss: 0.005511223338544369
Loss: 0.00323388259857893
Loss: 0.003060918068513274
Loss: 0.0014598327688872814
Loss: 0.0029467763379216194
Loss: 0.0019636857323348522
Loss: 0.0029881298542022705
Loss: 0.003737600753083825
Loss: 0.0018548276275396347
Loss: 0.003764562774449587
Loss: 0.001933353953063488
Loss: 0.0038498947396874428
Loss: 0.0020109922625124454
Loss: 0.003306977916508913
Loss: 0.003003603545948863
Loss: 0.002104909624904394
Loss: 0.00279107759706676
Loss: 0.003639447735622525
Loss: 0.0020939018577337265
Loss: 0.002889062277972698
Loss: 0.0029630670323967934
Loss: 0.002682890510186553
Loss: 0.0013446626253426075
Loss: 0.0031138225458562374
Loss: 0.0018564832862466574
Loss: 0.0037326044403016567
Loss: 0.0026669648941606283
Loss: 0.002767356112599373
Loss: 0.004275052808225155
Loss: 0.003092550439760089
Loss: 0.0017075975192710757
Loss: 0.00223206402733922
Loss: 0.004364036954939365
Loss: 0.0017717416631057858
Loss: 0.0022049746476113796
Loss: 0.003950855229049921
Loss: 0.0034157191403210163
Loss: 0.0021702395752072334
Loss: 0.002232858445495367
Loss: 0.0015527828363701701
Loss: 0.0022510045673698187
Loss: 0.002616903744637966
Loss: 0.002367899054661393
Loss: 0.005037573166191578
Loss: 0.0026634209789335728
Loss: 0.002684351522475481
Loss: 0.001967671327292919
Loss: 0.0029313922859728336
Loss: 0.0039417021907866
Loss: 0.0062031857669353485
Loss: 0.004413264337927103
Loss: 0.002050303388386965
Loss: 0.0030487647745758295
Loss: 0.001275954069569707
Loss: 0.00163930538110435
Loss: 0.003396248910576105
Loss: 0.001898116199299693
Loss: 0.001544890576042235
Loss: 0.0009917601710185409
Loss: 0.0015495645347982645
Loss: 0.0016437252052128315
Loss: 0.002781132934615016
Loss: 0.0022871154360473156
Loss: 0.003487700829282403
Loss: 0.003546991851180792
Loss: 0.0016631672624498606
Loss: 0.002287240233272314
Loss: 0.0021888576447963715
Loss: 0.0025085872039198875
Loss: 0.002312101423740387
Loss: 0.0018785371212288737
Loss: 0.004065977409482002
Loss: 0.0017008425202220678
Loss: 0.002616463229060173
Loss: 0.003800296224653721
Loss: 0.0018152015982195735
Loss: 0.0013732052175328135
Loss: 0.003690797835588455
Loss: 0.006783472374081612
Loss: 0.001940306043252349
Loss: 0.001710426528006792
Loss: 0.0018281921511515975
Loss: 0.001912941224873066
Loss: 0.002554421778768301
Loss: 0.002484504599124193
Loss: 0.002402534242719412
Loss: 0.001840675249695778
Loss: 0.0017248776275664568
Loss: 0.0034443200565874577
Loss: 0.0020171909127384424
Loss: 0.0021571707911789417
Loss: 0.0021503730677068233
Loss: 0.0029751923866569996
Loss: 0.0019866214133799076
Loss: 0.0026325457729399204
Loss: 0.002685957122594118
Loss: 0.004479433875530958
Loss: 0.00500457501038909
Loss: 0.0017793953884392977
Loss: 0.003424592548981309
</code></pre>
</div>
</div>
<div id="8808dc13" class="cell markdown" id="8808dc13">
<h2 id="задание-5">Задание 5</h2>
<h3 id="генерация-с-помощью-обученной-консистенси-модели">Генерация с
помощью обученной консистенси модели</h3>
<p>Настало время погенерировать картинки с помощью нашей модели.
Напомним, что мы не можем для консистенси моделей использовать DDIM и
другие классические солверы для диффузии. Нам нужен специальный сэмплер
для CM, который схематично изображен на картинке ниже:</p>
<div>
<img src="https://storage.yandexcloud.net/yandex-research/cvweek-cd-task-images/cd-sampling-idea.jpg" width="600"/>
</div>
<p>Чуть более формально:</p>
<p><span
class="math inline"><em>x</em><sub><em>t</em><sub><em>n</em></sub></sub> ∼ <em>N</em>(0,<em>I</em>)</span></p>
<p><span
class="math inline"><em>f</em><em>o</em><em>r</em> <em>t</em><sub><em>i</em></sub> ∈ [<em>t</em><sub><em>n</em></sub>,...,<em>t</em><sub>1</sub>]:</span></p>
<ul>
<li><p><span
class="math inline"><em>ϵ</em> ← <em>u</em><em>n</em><em>e</em><em>t</em>(<em>x</em><sub><em>t</em><sub><em>i</em></sub></sub>)</span></p></li>
<li><p><span
class="math inline"><em>x</em><sub>0</sub> ← <em>D</em><em>D</em><em>I</em><em>M</em>(<em>ϵ</em>,<em>x</em><sub><em>t</em><sub><em>i</em></sub></sub>,<em>t</em><sub><em>i</em></sub>,0)</span></p></li>
<li><p><span
class="math inline"><em>x</em><sub><em>t</em><sub><em>i</em> − 1</sub></sub> ← <em>q</em>(<em>x</em><sub><em>t</em><sub><em>i</em> − 1</sub></sub>|<em>x</em><sub>0</sub>)</span></p></li>
</ul>
<p><strong>Classifier-free guidance (CFG)</strong></p>
<p>Также вам надо реализовать поддержку CFG в CM сэмплирование. Вспомним
формулу:</p>
<p><span class="math inline">$\epsilon_w =
{\color{blue}{\epsilon_{uncond}}} + w \cdot (\epsilon_{cond} -
\epsilon_{uncond})$</span>, где <span
class="math inline"><em>w</em> ≥ 1</span></p>
<p><strong>Обратим внимание</strong>, что режим "без гайденса"
соотвествует <span class="math inline"><em>w</em> = 1</span>, что
немного контринтуитивно, но в большинстве реализаций будет встречаться
именно такой вид этой формулы.</p>
</div>
<div id="6f1c47c2" class="cell code" data-execution_count="27"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T23:19:28.558856Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T23:19:28.558502Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T23:19:28.570211Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T23:19:28.569251Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T23:19:28.558829Z&quot;}"
id="6f1c47c2">
<div class="sourceCode" id="cb46"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="at">@torch.no_grad</span>()</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> consistency_sampling(</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    pipe,</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>    prompt,</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>    num_inference_steps<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>    generator<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>    num_images_per_prompt<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>    guidance_scale<span class="op">=</span><span class="dv">1</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> prompt <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> <span class="bu">isinstance</span>(prompt, <span class="bu">str</span>):</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> prompt <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> <span class="bu">isinstance</span>(prompt, <span class="bu">list</span>):</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> <span class="bu">len</span>(prompt)</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> pipe._execution_device</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Извлекаем эмбеды из текстовых промптов. Реализуйте вызов pipe.encode_prompt</span></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>    do_classifier_free_guidance <span class="op">=</span> guidance_scale <span class="op">&gt;</span> <span class="dv">0</span></span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>    prompt_embeds, null_prompt_embeds <span class="op">=</span> pipe.encode_prompt(prompt, device, num_images_per_prompt, do_classifier_free_guidance)</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> prompt_embeds.dtype <span class="op">==</span> null_prompt_embeds.dtype <span class="op">==</span> torch.float16</span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Настраиваем параметры scheduler-a</span></span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> pipe.scheduler.config[<span class="st">&#39;timestep_spacing&#39;</span>] <span class="op">==</span> <span class="st">&#39;trailing&#39;</span></span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a>    pipe.scheduler.set_timesteps(num_inference_steps)</span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Создаем батч латентов из N(0,I)</span></span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a>    latents <span class="op">=</span> torch.randn(size <span class="op">=</span> (num_images_per_prompt, <span class="dv">4</span>, <span class="dv">64</span>, <span class="dv">64</span>), device <span class="op">=</span> <span class="st">&#39;cuda&#39;</span>, generator <span class="op">=</span> generator).half()</span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, t <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(pipe.scheduler.timesteps)):</span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a>        t <span class="op">=</span> torch.tensor([t] <span class="op">*</span> <span class="bu">len</span>(latents)).to(device)</span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a>        zero_t <span class="op">=</span> torch.tensor([<span class="dv">0</span>] <span class="op">*</span> <span class="bu">len</span>(latents)).to(device)</span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-33"><a href="#cb46-33" aria-hidden="true" tabindex="-1"></a>        cond_noise_pred <span class="op">=</span> pipe.unet(latents, t, encoder_hidden_states<span class="op">=</span>prompt_embeds).sample</span>
<span id="cb46-34"><a href="#cb46-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-35"><a href="#cb46-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> do_classifier_free_guidance:</span>
<span id="cb46-36"><a href="#cb46-36" aria-hidden="true" tabindex="-1"></a>            uncond_noise_pred <span class="op">=</span> pipe.unet(latents, t, encoder_hidden_states<span class="op">=</span>null_prompt_embeds).sample</span>
<span id="cb46-37"><a href="#cb46-37" aria-hidden="true" tabindex="-1"></a>            noise_pred <span class="op">=</span> uncond_noise_pred <span class="op">+</span> guidance_scale <span class="op">*</span> (cond_noise_pred <span class="op">-</span> uncond_noise_pred)</span>
<span id="cb46-38"><a href="#cb46-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb46-39"><a href="#cb46-39" aria-hidden="true" tabindex="-1"></a>            noise_pred <span class="op">=</span> cond_noise_pred</span>
<span id="cb46-40"><a href="#cb46-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-41"><a href="#cb46-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Получаем x_0 оценку из x_t</span></span>
<span id="cb46-42"><a href="#cb46-42" aria-hidden="true" tabindex="-1"></a>        x_0 <span class="op">=</span> ddim_solver_step(noise_pred, latents, t, zero_t, pipe.scheduler)</span>
<span id="cb46-43"><a href="#cb46-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-44"><a href="#cb46-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-45"><a href="#cb46-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">+</span> <span class="dv">1</span> <span class="op">&lt;</span> num_inference_steps:</span>
<span id="cb46-46"><a href="#cb46-46" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Переход на следующий шаг</span></span>
<span id="cb46-47"><a href="#cb46-47" aria-hidden="true" tabindex="-1"></a>            s <span class="op">=</span> pipe.scheduler.timesteps[i<span class="op">+</span><span class="dv">1</span>]</span>
<span id="cb46-48"><a href="#cb46-48" aria-hidden="true" tabindex="-1"></a>            s <span class="op">=</span> torch.tensor([s] <span class="op">*</span> <span class="bu">len</span>(latents)).to(device)</span>
<span id="cb46-49"><a href="#cb46-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-50"><a href="#cb46-50" aria-hidden="true" tabindex="-1"></a>            latents <span class="op">=</span> q_sample(x_0, s, pipe.scheduler)</span>
<span id="cb46-51"><a href="#cb46-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-52"><a href="#cb46-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb46-53"><a href="#cb46-53" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Последний шаг</span></span>
<span id="cb46-54"><a href="#cb46-54" aria-hidden="true" tabindex="-1"></a>            latents <span class="op">=</span> x_0</span>
<span id="cb46-55"><a href="#cb46-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-56"><a href="#cb46-56" aria-hidden="true" tabindex="-1"></a>        latents <span class="op">=</span> latents.half()</span>
<span id="cb46-57"><a href="#cb46-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-58"><a href="#cb46-58" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> pipe.vae.decode(latents <span class="op">/</span> pipe.vae.config.scaling_factor, return_dict<span class="op">=</span><span class="va">False</span>)[<span class="dv">0</span>]</span>
<span id="cb46-59"><a href="#cb46-59" aria-hidden="true" tabindex="-1"></a>    do_denormalize <span class="op">=</span> [<span class="va">True</span>] <span class="op">*</span> image.shape[<span class="dv">0</span>]</span>
<span id="cb46-60"><a href="#cb46-60" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> pipe.image_processor.postprocess(image, output_type<span class="op">=</span><span class="st">&quot;pil&quot;</span>, do_denormalize<span class="op">=</span>do_denormalize)</span>
<span id="cb46-61"><a href="#cb46-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> image</span></code></pre></div>
</div>
<div id="57927112" class="cell markdown" id="&quot;57927112&quot;">
<p>Попробуем сгененировать что-то нашей моделью. Можно поиграться с
разными сидами и гайденс скейлами.</p>
<p>Референс, что примерно должно получиться на этом этапе для
guidance_scale=2. Как видите, картинки стали почетче, но пока все еще
так себе.</p>
<p><img
src="https://storage.yandexcloud.net/yandex-research/cvweek-cd-task-images/reference-ct.png"
alt="img" /></p>
</div>
<div id="cf2dc5a8" class="cell code" data-execution_count="28"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T23:19:40.808542Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T23:19:40.807714Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T23:19:46.129676Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T23:19:46.128837Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T23:19:40.808497Z&quot;}"
id="cf2dc5a8">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>pipe.unet <span class="op">=</span> cm_unet.<span class="bu">eval</span>().to(torch.float16)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> cm_unet.active_adapter <span class="op">==</span> <span class="st">&#39;ct&#39;</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>generator <span class="op">=</span> torch.Generator(device<span class="op">=</span><span class="st">&quot;cuda&quot;</span>).manual_seed(<span class="dv">1</span>)</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>guidance_scale <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Заменяем генерацию пайплайном на наше сэмплирование.</span></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> consistency_sampling(</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>    pipe,</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>    prompt,</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>    num_inference_steps<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>    generator<span class="op">=</span>generator,</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>    num_images_per_prompt<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>    guidance_scale<span class="op">=</span>guidance_scale</span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>visualize_images(images)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb48"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;5165d231df8149b9bbbe64250c30a765&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/23d89094099141f1022e11cb98ab856fd8b42ed2.png" /></p>
</div>
</div>
<div id="11670976" class="cell markdown" id="&quot;11670976&quot;">
<h1 id="consistency-distillation">Consistency Distillation</h1>
<h2 id="задание-6">Задание №6</h2>
<p>Теперь давайте попробуем перейти к постановке дистилляции, где шаг из
<span class="math inline"><em>x</em><sub><em>t</em></sub></span> в <span
class="math inline"><em>x</em><sub><em>s</em></sub></span> будет
делаться не аналитически, а c помощью модели учителя.</p>
<p><span
class="math inline"><strong>x</strong><sub><em>t</em></sub> = <em>q</em>(<strong>x</strong><sub><em>t</em></sub>|<strong>x</strong><sub>0</sub>)</span></p>
<p><span
class="math inline"><strong>x</strong><sub><em>s</em></sub> = <em>D</em><em>D</em><em>I</em><em>M</em>(<em>ϵ</em><sub><em>θ</em></sub>(<strong>x</strong><sub><em>t</em></sub>,<em>t</em>),<strong>x</strong><sub><em>t</em></sub>,<em>t</em>,<em>s</em>)</span></p>
<p><strong>Замечание:</strong> В text-to-image генерации
<em>classifier-free guidance (CFG)</em> играет очень важную роль для
получения хорошего качества с помощью диффузии. CFG меняет траектории
ODE и раз нам он важен, то давайте и дистиллировать траектории с
CFG.</p>
<p>Поэтому для получения точки <span
class="math inline"><strong>x</strong><sub><em>s</em></sub></span> мы
будем использовать шаг учителя с CFG. Это важное отличие от CT сеттинга
- там мы не можем моделировать гайденс.</p>
</div>
<div id="2944a46d-cc08-43a4-aff6-896cf114c767" class="cell code"
data-execution_count="30"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T23:20:59.854753Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T23:20:59.854009Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T23:20:59.936762Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T23:20:59.935858Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T23:20:59.854719Z&quot;}">
<div class="sourceCode" id="cb49"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>torch.cuda.empty_cache()</span></code></pre></div>
</div>
<div id="98399cfb" class="cell code" data-execution_count="31"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T23:21:12.509360Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T23:21:12.509008Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T23:21:13.917256Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T23:21:13.916308Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T23:21:12.509329Z&quot;}"
id="98399cfb">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>unet <span class="op">=</span> unet.to(torch.float32)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>unet.train()</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> unet.dtype <span class="op">==</span> torch.float32</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Добавляем новые LoRA адаптеры для CD модели</span></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>cm_unet.add_adapter(<span class="st">&quot;cd&quot;</span>, lora_config)</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>cm_unet.set_adapter(<span class="st">&quot;cd&quot;</span>)</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Пересоздаем оптимизатор</span></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.AdamW(cm_unet.parameters(), lr<span class="op">=</span><span class="fl">1e-4</span>)</span></code></pre></div>
</div>
<div id="67eda898" class="cell code" data-execution_count="32"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T23:21:18.480212Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T23:21:18.479869Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T23:21:18.486819Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T23:21:18.485935Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T23:21:18.480182Z&quot;}"
id="67eda898">
<div class="sourceCode" id="cb51"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="at">@torch.no_grad</span>()</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_xs_from_xt_with_teacher(</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>    x_0, x_t, t, s, <span class="co"># Не все эти аргументы могут быть вам нужны</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>    scheduler,</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>    prompt_embeds,</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>    teacher_unet,</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>    guidance_scale,</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>kwargs</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Делаем предсказание учителем в кондишион случае: подаем эмбеды текста</span></span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>    cond_noise_pred <span class="op">=</span> teacher_unet(x_t, t, encoder_hidden_states<span class="op">=</span>prompt_embeds).sample</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Для CFG нам нужно делать предсказания в unconditional случае.</span></span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Для T2I моделей, мы будем это моделировать предсказаниями для пустого промпта &quot;&quot;</span></span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Извлечем эмбеды из пустого промпта и размножить их до размера батча</span></span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>    uncond_input_ids <span class="op">=</span> pipe.tokenizer(</span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a>        [<span class="st">&quot;&quot;</span>], return_tensors<span class="op">=</span><span class="st">&quot;pt&quot;</span>, padding<span class="op">=</span><span class="st">&quot;max_length&quot;</span>, max_length<span class="op">=</span><span class="dv">77</span></span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>    ).input_ids.to(<span class="st">&quot;cuda&quot;</span>)</span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a>    uncond_prompt_embeds <span class="op">=</span> pipe.text_encoder(uncond_input_ids)[<span class="dv">0</span>].expand(</span>
<span id="cb51-21"><a href="#cb51-21" aria-hidden="true" tabindex="-1"></a>        <span class="op">*</span>prompt_embeds.shape</span>
<span id="cb51-22"><a href="#cb51-22" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb51-23"><a href="#cb51-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-24"><a href="#cb51-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Затем прогоняем модель для пустых промптов</span></span>
<span id="cb51-25"><a href="#cb51-25" aria-hidden="true" tabindex="-1"></a>    uncond_noise_pred <span class="op">=</span> teacher_unet(x_t, t, encoder_hidden_states<span class="op">=</span>uncond_prompt_embeds).sample</span>
<span id="cb51-26"><a href="#cb51-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-27"><a href="#cb51-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Применяем CFG формулу и получаем итоговый предикт учителя</span></span>
<span id="cb51-28"><a href="#cb51-28" aria-hidden="true" tabindex="-1"></a>    noise_pred <span class="op">=</span> uncond_noise_pred <span class="op">+</span> guidance_scale <span class="op">*</span> (cond_noise_pred <span class="op">-</span> uncond_noise_pred)</span>
<span id="cb51-29"><a href="#cb51-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-30"><a href="#cb51-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Получаем x_s из x_t</span></span>
<span id="cb51-31"><a href="#cb51-31" aria-hidden="true" tabindex="-1"></a>    x_s <span class="op">=</span> ddim_solver_step(noise_pred, x_t, t, s, pipe.scheduler)</span>
<span id="cb51-32"><a href="#cb51-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_s</span>
<span id="cb51-33"><a href="#cb51-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-34"><a href="#cb51-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-35"><a href="#cb51-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Сразу зададим внутрь модель учителя и guidance_scale</span></span>
<span id="cb51-36"><a href="#cb51-36" aria-hidden="true" tabindex="-1"></a>get_xs_from_xt_with_teacher <span class="op">=</span> functools.partial(</span>
<span id="cb51-37"><a href="#cb51-37" aria-hidden="true" tabindex="-1"></a>    get_xs_from_xt_with_teacher,</span>
<span id="cb51-38"><a href="#cb51-38" aria-hidden="true" tabindex="-1"></a>    teacher_unet<span class="op">=</span>teacher_unet,</span>
<span id="cb51-39"><a href="#cb51-39" aria-hidden="true" tabindex="-1"></a>    guidance_scale<span class="op">=</span><span class="fl">7.5</span></span>
<span id="cb51-40"><a href="#cb51-40" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="765f39be" class="cell markdown" id="765f39be">
<p>Еще, как показано в работе <a
href="https://arxiv.org/pdf/2310.14189">Improved Techniques for Training
Consistency Models</a>. L2 лосс не самый оптимальный выбор для
консистенси моделей. Давайте в CD обучении также заменим MSE лосс на
pseudo-huber лосс из статьи.</p>
</div>
<div id="878a5bac" class="cell code" data-execution_count="33"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T23:21:22.584812Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T23:21:22.584427Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T23:21:22.589597Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T23:21:22.588579Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T23:21:22.584783Z&quot;}"
id="878a5bac">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pseudo_huber_loss(</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>    x: torch.Tensor,</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>    y: torch.Tensor,</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>    c<span class="op">=</span><span class="fl">0.001</span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> (torch.sqrt(((x <span class="op">-</span> y)<span class="op">**</span><span class="dv">2</span>).<span class="bu">sum</span>() <span class="op">+</span> c<span class="op">**</span><span class="dv">2</span>) <span class="op">-</span> c)<span class="op">/</span>x.shape[<span class="dv">0</span>]</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss</span></code></pre></div>
</div>
<div id="12855c88" class="cell code" data-execution_count="34"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T23:21:24.343006Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T23:21:24.342268Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-05T23:21:24.347045Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-05T23:21:24.346103Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T23:21:24.342973Z&quot;}"
id="12855c88">
<div class="sourceCode" id="cb53"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>cd_loss <span class="op">=</span> functools.partial(</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>    cm_loss_template,</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>    loss_fn<span class="op">=</span>pseudo_huber_loss,</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>    get_boundary_timesteps<span class="op">=</span>get_zero_boundary_timesteps,</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>    get_xs_from_xt<span class="op">=</span>get_xs_from_xt_with_teacher</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> cm_unet.active_adapter <span class="op">==</span> <span class="st">&#39;cd&#39;</span></span></code></pre></div>
</div>
<div id="79db78ad" class="cell markdown" id="79db78ad">
<p><strong>Теперь обучим модель в CD режиме</strong></p>
</div>
<div id="a3035cf7" class="cell code" data-execution_count="35"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-05T23:21:27.988926Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-05T23:21:27.988099Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-06T00:32:09.840930Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-06T00:32:09.839944Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-05T23:21:27.988890Z&quot;}"
id="a3035cf7">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>num_grad_accum <span class="op">=</span> <span class="dv">2</span> <span class="co"># обновляем параметры каждые 2 шага</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>train_loop(cm_unet, pipe, train_dataloader, optimizer, cd_loss, num_grad_accum)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb55"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;ded903b50f044c6897b64b717500170d&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Loss: 2.944845676422119
Loss: 3.3592944145202637
Loss: 2.381946325302124
Loss: 2.730635643005371
Loss: 2.035524606704712
Loss: 2.5971450805664062
Loss: 2.854871988296509
Loss: 1.7238147258758545
Loss: 2.7196664810180664
Loss: 2.801090717315674
Loss: 2.6288421154022217
Loss: 1.7691832780838013
Loss: 1.1831740140914917
Loss: 1.5165297985076904
Loss: 2.056777238845825
Loss: 2.7573704719543457
Loss: 3.375680923461914
Loss: 1.7772654294967651
Loss: 1.9639902114868164
Loss: 2.5408880710601807
Loss: 2.7827703952789307
Loss: 1.8280611038208008
Loss: 2.9609181880950928
Loss: 2.756485939025879
Loss: 2.7222585678100586
Loss: 2.033778667449951
Loss: 2.3296360969543457
Loss: 2.202174425125122
Loss: 2.526829481124878
Loss: 2.7064690589904785
Loss: 3.0036303997039795
Loss: 1.4907933473587036
Loss: 1.8400686979293823
Loss: 1.7597579956054688
Loss: 2.6982245445251465
Loss: 2.385591745376587
Loss: 1.6883586645126343
Loss: 2.3403866291046143
Loss: 1.4785760641098022
Loss: 2.4371471405029297
Loss: 2.4056789875030518
Loss: 1.8712458610534668
Loss: 1.98939847946167
Loss: 1.7566754817962646
Loss: 2.5757179260253906
Loss: 1.390453577041626
Loss: 2.155431032180786
Loss: 3.155982732772827
Loss: 3.577787160873413
Loss: 2.2384231090545654
Loss: 3.019151210784912
Loss: 2.303292751312256
Loss: 2.351811647415161
Loss: 3.6605260372161865
Loss: 2.4715538024902344
Loss: 2.5303475856781006
Loss: 2.9664242267608643
Loss: 3.077784538269043
Loss: 2.678936004638672
Loss: 2.520132303237915
Loss: 3.1518871784210205
Loss: 2.8704898357391357
Loss: 3.2255942821502686
Loss: 3.1522538661956787
Loss: 1.62734854221344
Loss: 1.8809494972229004
Loss: 2.6644537448883057
Loss: 2.037371873855591
Loss: 2.2126567363739014
Loss: 4.574580669403076
Loss: 1.8539665937423706
Loss: 4.31126594543457
Loss: 3.2715823650360107
Loss: 3.6714704036712646
Loss: 5.593667984008789
Loss: 3.6599152088165283
Loss: 3.540663480758667
Loss: 4.6081085205078125
Loss: 4.434865474700928
Loss: 3.9987378120422363
Loss: 3.6672523021698
Loss: 4.2815351486206055
Loss: 4.962001800537109
Loss: 3.028421640396118
Loss: 3.0425686836242676
Loss: 1.5648400783538818
Loss: 3.762638568878174
Loss: 5.747701168060303
Loss: 4.088062763214111
Loss: 5.96066427230835
Loss: 4.506356716156006
Loss: 8.883935928344727
Loss: 5.051792621612549
Loss: 3.815391778945923
Loss: 5.237568378448486
Loss: 4.080380439758301
Loss: 2.818108081817627
Loss: 6.817370414733887
Loss: 2.6235568523406982
Loss: 5.879570484161377
Loss: 5.1829447746276855
Loss: 3.1784822940826416
Loss: 2.5371949672698975
Loss: 4.127660274505615
Loss: 4.0053534507751465
Loss: 4.654754638671875
Loss: 2.9779927730560303
Loss: 2.121793031692505
Loss: 10.121045112609863
Loss: 3.3680877685546875
Loss: 4.222323894500732
Loss: 4.134800910949707
Loss: 3.597766876220703
Loss: 3.1363508701324463
Loss: 5.953597068786621
Loss: 6.0252299308776855
Loss: 3.7766294479370117
Loss: 6.822202682495117
Loss: 2.4231081008911133
Loss: 2.6728758811950684
Loss: 4.003442287445068
Loss: 6.01810359954834
Loss: 2.497846841812134
Loss: 2.4085328578948975
Loss: 7.668595314025879
Loss: 2.438230276107788
Loss: 5.533960342407227
Loss: 13.33078670501709
Loss: 3.763178586959839
Loss: 4.0918803215026855
Loss: 3.6613738536834717
Loss: 3.4524166584014893
Loss: 3.2709288597106934
Loss: 3.5976080894470215
Loss: 5.556673526763916
Loss: 3.5104587078094482
Loss: 2.8643417358398438
Loss: 4.952646255493164
Loss: 3.7257912158966064
Loss: 2.540724277496338
Loss: 3.4176254272460938
Loss: 4.5354719161987305
Loss: 5.326205253601074
Loss: 2.581998825073242
Loss: 2.6421210765838623
Loss: 5.969613552093506
Loss: 3.0565121173858643
Loss: 2.26265025138855
Loss: 3.7350385189056396
Loss: 3.848937749862671
Loss: 5.105525970458984
Loss: 2.5255062580108643
Loss: 2.533264636993408
Loss: 2.9169790744781494
Loss: 3.6729838848114014
Loss: 4.019057750701904
Loss: 3.8382112979888916
Loss: 3.3029110431671143
Loss: 3.3116257190704346
Loss: 4.636557579040527
Loss: 3.4108123779296875
Loss: 1.8477203845977783
Loss: 3.0417237281799316
Loss: 3.812586784362793
Loss: 3.8046717643737793
Loss: 3.8939075469970703
Loss: 3.1101529598236084
Loss: 4.3802900314331055
Loss: 1.5927709341049194
Loss: 4.691198348999023
Loss: 3.076223134994507
Loss: 2.6408374309539795
Loss: 4.558244705200195
Loss: 3.294841766357422
Loss: 2.908219814300537
Loss: 4.391512393951416
Loss: 4.28202486038208
Loss: 2.4056477546691895
Loss: 3.6809117794036865
Loss: 4.812608242034912
Loss: 4.00543737411499
Loss: 3.8937315940856934
Loss: 5.4202799797058105
Loss: 3.4569921493530273
Loss: 3.4715194702148438
Loss: 3.580169916152954
Loss: 4.267617225646973
Loss: 5.722354888916016
Loss: 3.43473482131958
Loss: 3.879180908203125
Loss: 6.413536548614502
Loss: 2.801511526107788
Loss: 2.915631055831909
Loss: 5.773158073425293
Loss: 2.7811198234558105
Loss: 3.2590854167938232
Loss: 2.9047911167144775
Loss: 2.695300817489624
Loss: 6.339973449707031
Loss: 2.581695318222046
Loss: 2.455322027206421
Loss: 5.648895740509033
Loss: 4.020227909088135
Loss: 3.429093360900879
Loss: 3.023991346359253
Loss: 2.8625948429107666
Loss: 3.058828592300415
Loss: 4.380131244659424
Loss: 2.497178554534912
Loss: 3.1372900009155273
Loss: 3.683769464492798
Loss: 3.28843092918396
Loss: 2.124140977859497
Loss: 2.187227964401245
Loss: 5.862614154815674
Loss: 3.765439987182617
Loss: 2.6485202312469482
Loss: 3.055624008178711
Loss: 3.2693684101104736
Loss: 2.3067798614501953
Loss: 3.532813310623169
Loss: 5.492265701293945
Loss: 3.98408842086792
Loss: 4.335119247436523
Loss: 3.4186670780181885
Loss: 4.433335781097412
Loss: 3.896120548248291
Loss: 3.3094303607940674
Loss: 4.659107685089111
Loss: 2.339210271835327
Loss: 4.126115322113037
Loss: 2.8857412338256836
Loss: 3.596003532409668
Loss: 4.597805500030518
Loss: 3.3493764400482178
Loss: 4.23816442489624
Loss: 2.0443367958068848
Loss: 2.877441167831421
Loss: 1.9619817733764648
Loss: 2.995964765548706
Loss: 3.5845649242401123
Loss: 7.290894508361816
Loss: 4.822551727294922
Loss: 4.065969467163086
Loss: 1.6498186588287354
Loss: 3.375049352645874
Loss: 3.955026865005493
Loss: 3.1089344024658203
Loss: 3.3492391109466553
Loss: 6.396028995513916
Loss: 3.9493844509124756
Loss: 4.043019771575928
Loss: 4.128828048706055
Loss: 4.090876579284668
Loss: 5.153146266937256
Loss: 3.0192904472351074
Loss: 3.6017346382141113
Loss: 3.486125946044922
Loss: 3.2913427352905273
Loss: 7.515349864959717
Loss: 2.871614694595337
Loss: 3.1312990188598633
Loss: 7.214624881744385
Loss: 2.4644782543182373
Loss: 4.083196640014648
Loss: 2.3445818424224854
Loss: 2.713740825653076
Loss: 4.743987560272217
Loss: 3.755622386932373
Loss: 4.682607173919678
Loss: 3.95139741897583
Loss: 2.9811177253723145
Loss: 3.7282564640045166
Loss: 2.7956185340881348
Loss: 5.041337013244629
Loss: 2.713733673095703
Loss: 3.6301076412200928
Loss: 3.628479242324829
Loss: 4.582287311553955
Loss: 2.600461483001709
Loss: 5.85031270980835
Loss: 6.068046569824219
Loss: 3.7673861980438232
Loss: 3.8268861770629883
Loss: 3.1123507022857666
Loss: 3.346189498901367
Loss: 4.9791131019592285
Loss: 7.099228382110596
Loss: 4.9963698387146
Loss: 2.950132369995117
Loss: 3.0072550773620605
Loss: 5.44942569732666
Loss: 4.947612762451172
Loss: 3.161327838897705
Loss: 3.353560209274292
Loss: 3.2946994304656982
Loss: 4.276927947998047
Loss: 2.884023666381836
Loss: 3.5706167221069336
Loss: 6.496044635772705
Loss: 5.23622465133667
Loss: 1.5885580778121948
Loss: 5.334719181060791
Loss: 6.926113128662109
Loss: 2.9376871585845947
Loss: 4.070377349853516
Loss: 4.361745834350586
Loss: 7.11747932434082
Loss: 6.497895240783691
Loss: 4.400742053985596
Loss: 3.7998507022857666
Loss: 4.2267303466796875
Loss: 3.3784468173980713
Loss: 3.655330181121826
Loss: 4.569136142730713
Loss: 3.2498068809509277
Loss: 2.7739531993865967
Loss: 3.4834563732147217
Loss: 4.041931629180908
Loss: 4.310549736022949
Loss: 3.122404098510742
Loss: 2.3919894695281982
Loss: 4.204408168792725
Loss: 4.080610275268555
Loss: 5.728775978088379
Loss: 4.242546081542969
Loss: 4.767579078674316
Loss: 5.240124225616455
Loss: 3.1524977684020996
Loss: 2.9962470531463623
Loss: 3.7547976970672607
Loss: 3.621800184249878
Loss: 3.236811637878418
Loss: 1.99314546585083
Loss: 3.649221658706665
Loss: 7.458519458770752
Loss: 4.335379600524902
Loss: 4.265073299407959
Loss: 3.642970561981201
Loss: 5.144977569580078
Loss: 4.402869701385498
Loss: 2.999410390853882
Loss: 5.104820251464844
Loss: 2.4585049152374268
Loss: 4.690229415893555
Loss: 4.218785285949707
Loss: 3.2148332595825195
Loss: 4.2795538902282715
Loss: 5.025773048400879
Loss: 4.461870193481445
Loss: 4.292713642120361
Loss: 5.874448299407959
Loss: 4.669053554534912
Loss: 3.8915650844573975
Loss: 2.8568737506866455
Loss: 2.690983772277832
Loss: 3.3325631618499756
Loss: 2.505890130996704
Loss: 4.104322910308838
Loss: 5.216023921966553
Loss: 2.2227272987365723
Loss: 7.155533313751221
Loss: 6.983233451843262
Loss: 4.00323486328125
Loss: 4.769155979156494
Loss: 4.4599080085754395
Loss: 3.8835666179656982
Loss: 3.9815828800201416
Loss: 4.19408655166626
Loss: 4.2940993309021
Loss: 4.98140287399292
Loss: 3.3898439407348633
Loss: 3.095750331878662
Loss: 3.6576147079467773
Loss: 4.260138511657715
Loss: 4.070141315460205
Loss: 3.0762646198272705
Loss: 2.033461332321167
Loss: 4.710902214050293
Loss: 8.827498435974121
Loss: 3.180777072906494
Loss: 4.125644683837891
Loss: 2.955411434173584
Loss: 4.515376567840576
Loss: 5.61498498916626
Loss: 1.490211009979248
Loss: 1.9978916645050049
Loss: 4.418766021728516
Loss: 5.202310562133789
Loss: 4.388569355010986
Loss: 5.606717586517334
Loss: 5.186674118041992
Loss: 1.8827718496322632
Loss: 2.1043860912323
Loss: 2.7388367652893066
Loss: 2.658522129058838
Loss: 2.2387020587921143
Loss: 4.184206485748291
Loss: 6.307335376739502
Loss: 2.5354764461517334
Loss: 4.760917663574219
Loss: 3.255544662475586
Loss: 4.955854415893555
Loss: 2.6245553493499756
Loss: 4.904417037963867
Loss: 4.533708572387695
Loss: 4.294952869415283
Loss: 3.377692699432373
Loss: 4.078911304473877
Loss: 4.242061614990234
Loss: 3.7331902980804443
Loss: 4.066569805145264
Loss: 4.25869607925415
Loss: 5.1510009765625
Loss: 4.111136436462402
Loss: 2.1453182697296143
Loss: 3.0505824089050293
Loss: 3.9722626209259033
Loss: 5.079751968383789
Loss: 4.4209885597229
Loss: 2.5313076972961426
Loss: 2.730365037918091
Loss: 5.093130588531494
Loss: 4.466552257537842
Loss: 2.509732246398926
Loss: 3.4201748371124268
Loss: 4.762739658355713
Loss: 3.225839376449585
Loss: 4.590313911437988
Loss: 3.685894727706909
Loss: 5.045645236968994
Loss: 3.666969060897827
Loss: 3.6615405082702637
Loss: 4.95820426940918
Loss: 4.744885444641113
Loss: 3.961134910583496
Loss: 3.9552550315856934
Loss: 2.086712121963501
Loss: 4.729014873504639
Loss: 1.9474613666534424
Loss: 5.852367401123047
Loss: 3.985966444015503
Loss: 5.647897243499756
Loss: 3.557522773742676
Loss: 4.638920783996582
Loss: 3.711400270462036
Loss: 5.334746837615967
Loss: 3.6971848011016846
Loss: 3.2904176712036133
Loss: 2.318460464477539
Loss: 3.277784824371338
Loss: 5.587253093719482
Loss: 3.771650552749634
Loss: 5.002555847167969
Loss: 3.840320348739624
Loss: 3.8398993015289307
Loss: 3.781169891357422
Loss: 4.546640872955322
Loss: 3.421541213989258
Loss: 1.308726191520691
Loss: 1.7788456678390503
Loss: 2.925372838973999
Loss: 3.6718616485595703
Loss: 4.412286281585693
Loss: 3.0450217723846436
Loss: 5.778335094451904
Loss: 4.4907684326171875
Loss: 4.315311908721924
Loss: 4.153057098388672
Loss: 2.3347561359405518
Loss: 4.447954177856445
Loss: 4.752626419067383
Loss: 2.2587130069732666
Loss: 4.060230255126953
Loss: 6.712137222290039
Loss: 6.435342311859131
Loss: 4.35470724105835
Loss: 2.4849045276641846
Loss: 3.936309576034546
Loss: 3.022681474685669
Loss: 2.3550190925598145
Loss: 5.49505090713501
Loss: 5.216493606567383
Loss: 5.790512561798096
Loss: 3.9551033973693848
Loss: 5.253077030181885
Loss: 4.017743110656738
Loss: 4.595279693603516
Loss: 4.413617134094238
Loss: 3.060620069503784
Loss: 1.885765552520752
Loss: 1.2648701667785645
Loss: 3.4439611434936523
Loss: 2.974104881286621
Loss: 3.192991018295288
Loss: 4.296292781829834
Loss: 4.121109962463379
Loss: 2.856726884841919
Loss: 3.9122588634490967
Loss: 6.480186462402344
Loss: 3.022326946258545
Loss: 3.142054319381714
Loss: 2.861201286315918
Loss: 3.3448069095611572
Loss: 4.074718475341797
Loss: 4.805400371551514
Loss: 5.402805805206299
Loss: 4.781680107116699
Loss: 2.6183602809906006
Loss: 5.633890151977539
Loss: 5.770367622375488
Loss: 4.071646213531494
Loss: 4.642374515533447
Loss: 3.4052178859710693
Loss: 4.684835910797119
Loss: 3.119851589202881
Loss: 3.7355141639709473
Loss: 5.078607559204102
Loss: 3.353025436401367
Loss: 4.9428629875183105
Loss: 0.9501233696937561
Loss: 3.7746284008026123
Loss: 2.6460962295532227
Loss: 4.7349443435668945
Loss: 2.9599366188049316
Loss: 4.441577434539795
Loss: 5.611800670623779
Loss: 4.180330753326416
Loss: 3.7827932834625244
Loss: 3.6490659713745117
Loss: 2.5793261528015137
Loss: 4.225381851196289
Loss: 5.3755621910095215
Loss: 4.981503009796143
Loss: 2.7980027198791504
Loss: 2.321617364883423
Loss: 4.480408668518066
Loss: 3.286722421646118
Loss: 2.5995054244995117
Loss: 3.898534059524536
Loss: 4.918566703796387
Loss: 5.289073467254639
Loss: 3.9149179458618164
Loss: 3.7349801063537598
Loss: 5.621278285980225
Loss: 3.164090394973755
Loss: 5.435731887817383
Loss: 3.867845296859741
Loss: 3.842507839202881
Loss: 6.223978042602539
Loss: 3.470451831817627
Loss: 5.434546947479248
Loss: 3.2497565746307373
Loss: 4.316061496734619
Loss: 6.052121639251709
Loss: 3.985349178314209
Loss: 6.437894821166992
Loss: 4.556546211242676
Loss: 5.0407938957214355
Loss: 4.303144931793213
Loss: 4.568287372589111
Loss: 5.942849159240723
Loss: 3.4656805992126465
Loss: 4.302785873413086
Loss: 4.221004486083984
Loss: 7.306042194366455
Loss: 3.914078712463379
Loss: 4.403112888336182
Loss: 2.3145105838775635
Loss: 4.748497009277344
Loss: 4.0385942459106445
Loss: 2.3941264152526855
Loss: 2.985016345977783
Loss: 3.8997504711151123
Loss: 4.035514831542969
Loss: 4.287654399871826
Loss: 4.948790073394775
Loss: 4.7545318603515625
Loss: 1.9182158708572388
Loss: 4.110651969909668
Loss: 4.42917537689209
Loss: 2.584193229675293
Loss: 2.383406639099121
Loss: 3.718860149383545
Loss: 4.894988536834717
Loss: 4.211278438568115
Loss: 4.225742340087891
Loss: 1.8635103702545166
Loss: 1.9640820026397705
Loss: 3.2897121906280518
Loss: 4.5449628829956055
Loss: 4.299997329711914
Loss: 4.998324871063232
Loss: 3.431732416152954
Loss: 2.965745449066162
Loss: 3.769453287124634
Loss: 4.944704055786133
Loss: 5.01937198638916
Loss: 3.7474350929260254
Loss: 2.667487621307373
Loss: 3.9074456691741943
Loss: 5.935207366943359
Loss: 5.431253433227539
Loss: 2.9526050090789795
Loss: 4.058017730712891
Loss: 4.755570411682129
Loss: 4.3151469230651855
Loss: 3.5730302333831787
Loss: 3.445451021194458
Loss: 3.4964804649353027
Loss: 3.5449297428131104
Loss: 3.6354548931121826
Loss: 2.5269389152526855
Loss: 2.493046283721924
Loss: 3.0827317237854004
Loss: 4.574130058288574
Loss: 3.253234624862671
Loss: 4.439281940460205
Loss: 2.620638132095337
Loss: 2.6046881675720215
Loss: 3.701408624649048
Loss: 3.4004647731781006
Loss: 4.846933364868164
Loss: 5.037989139556885
Loss: 5.073561191558838
</code></pre>
</div>
</div>
<div id="971622aa" class="cell markdown" id="971622aa">
<h3 id="снова-сэмплируем">Снова сэмплируем</h3>
<p>Обратим внимание, что тут мы сэмпилруем без гайденса, потому что мы
его уже частично прокинули в модель, когда делали шаг учителя с CFG.</p>
<p>Снова для референса приводим картинки на этом этапе:</p>
<p><img
src="https://storage.yandexcloud.net/yandex-research/cvweek-cd-task-images/reference-cd.png"
alt="img" /></p>
<p><strong>Ваши картинки не обязаны совпадать: у вас могут быть немного
менее/более качественные. Небольшая разница по качеству на оценку не
влиет.</strong></p>
</div>
<div id="46e13eb6" class="cell code" data-execution_count="36"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-06T00:38:06.967515Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-06T00:38:06.966894Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-06T00:38:12.259618Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-06T00:38:12.258755Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-06T00:38:06.967478Z&quot;}"
id="46e13eb6">
<div class="sourceCode" id="cb57"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Подставляем нашу новую обученную модель в пайплайн</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>pipe.unet <span class="op">=</span> cm_unet.<span class="bu">eval</span>().to(torch.float16)</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> cm_unet.active_adapter <span class="op">==</span> <span class="st">&#39;cd&#39;</span></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>generator <span class="op">=</span> torch.Generator(device<span class="op">=</span><span class="st">&quot;cuda&quot;</span>).manual_seed(<span class="dv">0</span>)</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>guidance_scale <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> consistency_sampling(</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>    pipe,</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>    prompt,</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>    num_inference_steps<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>    generator<span class="op">=</span>generator,</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>    num_images_per_prompt<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>    guidance_scale<span class="op">=</span>guidance_scale</span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a>visualize_images(images)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb58"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;ef789fc99b3348bca5baafbc56046b78&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/2b62b4f7b321b0a2875350c2d8f8a81bbb2142c0.png" /></p>
</div>
</div>
<div id="30be7c1e" class="cell markdown" id="30be7c1e">
<h4 id="давайте-посмотрим-на-картинки-для-других-промптов">Давайте
посмотрим на картинки для других промптов</h4>
</div>
<div id="4bae76af" class="cell code" data-execution_count="37"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-06T00:38:24.052041Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-06T00:38:24.051214Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-06T00:39:04.798733Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-06T00:39:04.797851Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-06T00:38:24.052004Z&quot;}"
id="4bae76af">
<div class="sourceCode" id="cb59"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>validation_prompts <span class="op">=</span> [</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;A sad puppy with large eyes&quot;</span>,</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Astronaut in a jungle, cold color palette, muted colors, detailed, 8k&quot;</span>,</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece&quot;</span>,</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;A girl with pale blue hair and a cami tank top&quot;</span>,</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;A lighthouse in a giant wave, origami style&quot;</span>,</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;belle epoque, christmas, red house in the forest, photo realistic, 8k&quot;</span>,</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;A small cactus with a happy face in the Sahara desert&quot;</span>,</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Green commercial building with refrigerator and refrigeration units outside&quot;</span>,</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> prompt <span class="kw">in</span> validation_prompts:</span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a>    generator <span class="op">=</span> torch.Generator(device<span class="op">=</span><span class="st">&quot;cuda&quot;</span>).manual_seed(<span class="dv">0</span>)</span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-15"><a href="#cb59-15" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> consistency_sampling(</span>
<span id="cb59-16"><a href="#cb59-16" aria-hidden="true" tabindex="-1"></a>        pipe,</span>
<span id="cb59-17"><a href="#cb59-17" aria-hidden="true" tabindex="-1"></a>        prompt,</span>
<span id="cb59-18"><a href="#cb59-18" aria-hidden="true" tabindex="-1"></a>        num_inference_steps<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb59-19"><a href="#cb59-19" aria-hidden="true" tabindex="-1"></a>        generator<span class="op">=</span>generator,</span>
<span id="cb59-20"><a href="#cb59-20" aria-hidden="true" tabindex="-1"></a>        num_images_per_prompt<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb59-21"><a href="#cb59-21" aria-hidden="true" tabindex="-1"></a>        guidance_scale<span class="op">=</span>guidance_scale</span>
<span id="cb59-22"><a href="#cb59-22" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb59-23"><a href="#cb59-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-24"><a href="#cb59-24" aria-hidden="true" tabindex="-1"></a>    visualize_images(images)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb60"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;2662282cf0ce4683a4cac5892b9d8cff&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb61"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;d4156905a7c14b18b1212e35e9cac317&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb62"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;e05a4fd190544c3b97dfac161b52da7c&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb63"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;5c466993c1f84145bf606e127a7bf769&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb64"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;db9821d4c4e14d10b7626438a23a1d71&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb65"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;b18262a610324c2496bc23cd99e7cc2f&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb66"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;247a566cca5d4d99ae4fadd20045fa96&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb67"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;b8230a90701f4f3bb5ff63ada1afc429&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/fb5b42e6cc1b291ec6a460bf1fb3a60d123ab1f0.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/1145b35f7564e914bdd01192de6a2acccd5f641c.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/965e773d92898077c622694b9f824fe7d3ba3759.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/b01833c654c3dfbd621c7f32cb2ca0df9023bf07.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/2cf6bd8e7d5ce6d4db9c0bd9d1a21b8267875b66.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/049eeeb6db6a0d42f449b06755f1ecd6b638f7b3.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/cf5b214e404c4eaf994f95f5770c5f8f1e85fe93.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/499415bfebc91a83e25f7f129086564c16334674.png" /></p>
</div>
</div>
<div id="bddea092-fa93-4c5b-ab9b-8f388236eda2" class="cell code"
data-execution_count="39"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-06T00:39:38.377598Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-06T00:39:38.377174Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-06T00:39:38.450758Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-06T00:39:38.449298Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-06T00:39:38.377563Z&quot;}">
<div class="sourceCode" id="cb68"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>torch.cuda.empty_cache()</span></code></pre></div>
</div>
<div id="9294acc5" class="cell markdown" id="9294acc5">
<h1 id="multi-boundary-сonsistency-distillation">Multi-boundary
Сonsistency Distillation</h1>
<div>
<p><img src=https://storage.yandexcloud.net/yandex-research/cvweek-cd-task-images/multi-cd-idea.jpg width=600>
<div></p>
<p>В конце мы рассмотрим недавнюю модификацию CD, <em>Multi-boundary
CD</em>, где интегрируем не всю траекторию сразу и потом сэмплируем с
возвращением назад, а разбиваем траектории на <span
class="math inline"><em>K</em></span> отрезков и применяет CD внутри
каждого отрезка независимо. Например, на картинке выше у нас два
отрезка: зеленым и красным выделены две граничные точки. Для
классического CD, рассмотренного ранее, у нас только одна граничная
точка в <span class="math inline"><em>t</em> = 0</span></p>
<p><strong>Обратим внимание</strong>, что сэмплирование становится
детерминистичным и можно снова использовать DDIM солвер, где число шагов
равно числу интервалов <span class="math inline"><em>K</em></span>, на
которые мы разбили траектории во время обучения.</p>
<p>Этот метод гораздо лучше работает чем обычный CD, потому что решать
задачу CD на отрезках, а не на всей траектории, гораздо проще. В текущем
задании мы разобьем траекторию на <span
class="math inline"><em>K</em> = 4</span> отрезка.</p>
<p>Подробнее почитать можно в этой <a
href="https://arxiv.org/pdf/2403.06807">статье</a>.</p>
</div>
<div id="95f05839" class="cell markdown" id="95f05839">
<h2 id="задание-7-025-балла-сдается-в-контесте">Задание №7 (0.25 балла,
сдается в контесте)</h2>
<p>Ниже реализуйте функцию, которая для <span
class="math inline"><em>K</em> = 4</span> отрезков будет сопоставлять
таймстепам соответствующие граничные точки.</p>
<p>Например, для <span class="math inline"><em>K</em> = 2</span>
отрезков граничные точки будут: [0, 499]</p>
<p><span class="math inline">0 ≤ <em>t</em> &lt; 499</span> -&gt;
граничная точка - <span class="math inline">0</span></p>
<p><span class="math inline">499 ≤ <em>t</em> &lt; 999</span> -&gt;
граничная точка - <span class="math inline">499</span></p>
<p><strong>Замечание:</strong> помним, что интервал между <span
class="math inline"><em>t</em></span> и <span
class="math inline"><em>s</em></span> - 20 шагов.</p>
</div>
<div id="c7d2dbb2" class="cell code" data-execution_count="40"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-06T00:39:53.480055Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-06T00:39:53.479642Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-06T00:39:53.486121Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-06T00:39:53.485287Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-06T00:39:53.480018Z&quot;}"
id="c7d2dbb2">
<div class="sourceCode" id="cb69"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_multi_boundary_timesteps(</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>    timesteps,</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>    num_boundaries<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>    num_timesteps<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Для батча таймстепов определяем соответствующие граничные точки.</span></span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a><span class="co">    params:</span></span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a><span class="co">        timesteps: torch.Tensor(batch_size, device=&#39;cuda&#39;)</span></span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a><span class="co">    returns:</span></span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a><span class="co">        boundary_timesteps: torch.Tensor(batch_size, device=&#39;cuda&#39;)</span></span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Здесь важно повыводить timesteps и boundary_timesteps перед обучением, </span></span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># чтобы не перелетать граничные точки и при этом иногда попадать в них.</span></span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a>    step_size <span class="op">=</span> num_timesteps <span class="op">/</span> num_boundaries</span>
<span id="cb69-16"><a href="#cb69-16" aria-hidden="true" tabindex="-1"></a>    indexes <span class="op">=</span> <span class="bu">range</span>(num_boundaries, <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb69-17"><a href="#cb69-17" aria-hidden="true" tabindex="-1"></a>    ts <span class="op">=</span> step_size <span class="op">*</span> torch.tensor(indexes) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb69-18"><a href="#cb69-18" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> torch.clamp(ts <span class="op">-</span> step_size, <span class="bu">min</span><span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb69-19"><a href="#cb69-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb69-20"><a href="#cb69-20" aria-hidden="true" tabindex="-1"></a>    boundaries <span class="op">=</span> []</span>
<span id="cb69-21"><a href="#cb69-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> el <span class="kw">in</span> timesteps:</span>
<span id="cb69-22"><a href="#cb69-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> b <span class="kw">in</span> s:</span>
<span id="cb69-23"><a href="#cb69-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> el <span class="op">&gt;=</span> b:</span>
<span id="cb69-24"><a href="#cb69-24" aria-hidden="true" tabindex="-1"></a>                boundaries.append(<span class="bu">int</span>(b))</span>
<span id="cb69-25"><a href="#cb69-25" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb69-26"><a href="#cb69-26" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb69-27"><a href="#cb69-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.tensor(boundaries).cuda()</span></code></pre></div>
</div>
<div id="262ef1a1-db96-431a-be48-342c7490991d" class="cell code"
data-execution_count="41"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-06T00:40:34.186999Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-06T00:40:34.186274Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-06T00:40:35.625657Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-06T00:40:35.624892Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-06T00:40:34.186964Z&quot;}">
<div class="sourceCode" id="cb70"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>unet <span class="op">=</span> unet.to(torch.float32)</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>unet.train()</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> unet.dtype <span class="op">==</span> torch.float32</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Создаем обертку исходной UNet модели с LoRA адаптерами, используя библиотеку PEFT</span></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>cm_unet.add_adapter(<span class="st">&#39;multi-cd&#39;</span>, lora_config)</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>cm_unet.set_adapter(<span class="st">&#39;multi-cd&#39;</span>)</span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Включаем gradient checkpointing - важная техника для экономии памяти во время обучения</span></span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>cm_unet.enable_gradient_checkpointing()</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Создаем оптимизатор</span></span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.AdamW(cm_unet.parameters(), lr<span class="op">=</span><span class="fl">1e-4</span>)</span></code></pre></div>
</div>
<div id="c4c1c0eb" class="cell code" data-execution_count="42"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-06T00:40:37.764762Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-06T00:40:37.763899Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-06T00:40:37.768702Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-06T00:40:37.767811Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-06T00:40:37.764723Z&quot;}"
id="c4c1c0eb">
<div class="sourceCode" id="cb71"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>multi_cd_loss <span class="op">=</span> functools.partial(</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>    cm_loss_template,</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>    loss_fn<span class="op">=</span>pseudo_huber_loss,</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>    get_boundary_timesteps<span class="op">=</span>get_multi_boundary_timesteps,</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>    get_xs_from_xt<span class="op">=</span>get_xs_from_xt_with_teacher</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> cm_unet.active_adapter <span class="op">==</span> <span class="st">&#39;multi-cd&#39;</span></span></code></pre></div>
</div>
<div id="3d86175a" class="cell markdown" id="3d86175a">
<p><strong>Теперь обучим Multi-boundary CD модель</strong></p>
</div>
<div id="aded4086" class="cell code" data-execution_count="43"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-06T00:40:50.371040Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-06T00:40:50.370697Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-06T01:51:32.092069Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-06T01:51:32.091249Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-06T00:40:50.371010Z&quot;}"
id="aded4086">
<div class="sourceCode" id="cb72"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>num_grad_accum <span class="op">=</span> <span class="dv">2</span> <span class="co"># обновляем параметры каждые 2 шага</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>train_loop(cm_unet, pipe, train_dataloader, optimizer, multi_cd_loss, num_grad_accum)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb73"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;30a10734cfb24a18b5c48d8f20b3afc8&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Loss: 0.985549807548523
Loss: 0.6056421399116516
Loss: 0.8560450077056885
Loss: 0.5032570958137512
Loss: 0.8155555725097656
Loss: 0.6611200571060181
Loss: 0.8718084096908569
Loss: 0.6700862646102905
Loss: 0.7889962792396545
Loss: 0.6122429370880127
Loss: 0.6442139744758606
Loss: 0.6437645554542542
Loss: 0.6630457043647766
Loss: 0.8712257146835327
Loss: 0.7115795612335205
Loss: 1.2209031581878662
Loss: 0.6567739248275757
Loss: 0.8051437139511108
Loss: 0.750608503818512
Loss: 0.7612939476966858
Loss: 1.0883134603500366
Loss: 0.6455227732658386
Loss: 0.7889763116836548
Loss: 1.0035598278045654
Loss: 0.7887725830078125
Loss: 0.613060712814331
Loss: 0.7574728727340698
Loss: 0.6676972508430481
Loss: 0.8502077460289001
Loss: 0.850546658039093
Loss: 0.6495895981788635
Loss: 0.6936365962028503
Loss: 0.7922816276550293
Loss: 0.6653838753700256
Loss: 0.7545126080513
Loss: 0.9376077651977539
Loss: 0.8928964734077454
Loss: 0.8228869438171387
Loss: 0.7756451964378357
Loss: 1.1233103275299072
Loss: 0.9189850091934204
Loss: 0.5633863806724548
Loss: 0.5615247488021851
Loss: 0.6293079853057861
Loss: 0.761192798614502
Loss: 0.7723316550254822
Loss: 0.9218770265579224
Loss: 0.7019007205963135
Loss: 0.8650489449501038
Loss: 0.6111012697219849
Loss: 0.6721728444099426
Loss: 0.7468178868293762
Loss: 0.9487269520759583
Loss: 0.7490541338920593
Loss: 0.8206049203872681
Loss: 0.7866674065589905
Loss: 0.7547266483306885
Loss: 0.7153390049934387
Loss: 0.7036264538764954
Loss: 0.8119191527366638
Loss: 0.806438148021698
Loss: 0.7937555313110352
Loss: 0.8774627447128296
Loss: 1.0563234090805054
Loss: 0.7893567085266113
Loss: 0.6804420351982117
Loss: 0.6503090262413025
Loss: 0.6235077381134033
Loss: 0.7145141959190369
Loss: 0.9533318877220154
Loss: 0.8123188614845276
Loss: 0.7532519698143005
Loss: 1.1115353107452393
Loss: 0.7608305811882019
Loss: 0.8134702444076538
Loss: 0.8715448975563049
Loss: 0.9875084757804871
Loss: 0.7470447421073914
Loss: 0.7447993755340576
Loss: 0.7373276352882385
Loss: 0.7806631922721863
Loss: 0.8074710965156555
Loss: 0.7583518028259277
Loss: 0.9263507127761841
Loss: 0.8998605012893677
Loss: 0.7645015716552734
Loss: 1.064393401145935
Loss: 0.8024492263793945
Loss: 0.9463760256767273
Loss: 0.8176628947257996
Loss: 0.8217048048973083
Loss: 0.9143164157867432
Loss: 0.8130146861076355
Loss: 0.9153740406036377
Loss: 1.0411370992660522
Loss: 1.0295437574386597
Loss: 0.7631073594093323
Loss: 1.5191402435302734
Loss: 0.7968512177467346
Loss: 0.7913654446601868
Loss: 1.5648257732391357
Loss: 1.1780064105987549
Loss: 0.8873181939125061
Loss: 1.1608960628509521
Loss: 0.7834910750389099
Loss: 0.6728882789611816
Loss: 1.4109803438186646
Loss: 0.4719538986682892
Loss: 0.8594358563423157
Loss: 0.7273473143577576
Loss: 0.6589556336402893
Loss: 0.8118913769721985
Loss: 0.759703516960144
Loss: 1.1794277429580688
Loss: 0.7772072553634644
Loss: 0.8472477197647095
Loss: 0.5570999979972839
Loss: 0.6850472688674927
Loss: 0.8993798494338989
Loss: 1.0598934888839722
Loss: 0.7110038995742798
Loss: 0.6643216609954834
Loss: 0.8231236338615417
Loss: 0.7606509923934937
Loss: 0.8120972514152527
Loss: 1.2614421844482422
Loss: 1.0932849645614624
Loss: 0.9083279967308044
Loss: 0.8001682758331299
Loss: 0.8119202256202698
Loss: 0.7326716780662537
Loss: 0.7173980474472046
Loss: 0.7303755283355713
Loss: 0.8942598104476929
Loss: 0.6658975481987
Loss: 0.7661803364753723
Loss: 1.4289811849594116
Loss: 0.7696085572242737
Loss: 0.7983200550079346
Loss: 0.8594802618026733
Loss: 0.9135068655014038
Loss: 0.8175738453865051
Loss: 0.959200382232666
Loss: 1.0927314758300781
Loss: 1.1647124290466309
Loss: 0.99631267786026
Loss: 0.6977821588516235
Loss: 0.7122993469238281
Loss: 0.7427083849906921
Loss: 1.167717456817627
Loss: 1.1195635795593262
Loss: 0.854316234588623
Loss: 0.7370096445083618
Loss: 1.0955297946929932
Loss: 1.0255922079086304
Loss: 0.9780974388122559
Loss: 0.7098105549812317
Loss: 0.8465279936790466
Loss: 0.9603250622749329
Loss: 1.1619504690170288
Loss: 0.8110726475715637
Loss: 1.1717944145202637
Loss: 0.5570964813232422
Loss: 0.7471426129341125
Loss: 0.6669341921806335
Loss: 0.7090854048728943
Loss: 0.6720610857009888
Loss: 0.8899949193000793
Loss: 0.46315038204193115
Loss: 0.8389975428581238
Loss: 0.7038827538490295
Loss: 0.6743288040161133
Loss: 0.9292478561401367
Loss: 1.142390489578247
Loss: 0.9549940228462219
Loss: 0.6566362977027893
Loss: 1.0511822700500488
Loss: 0.6905691623687744
Loss: 0.6836581230163574
Loss: 0.6908953189849854
Loss: 0.6967553496360779
Loss: 1.0396918058395386
Loss: 0.7348542213439941
Loss: 1.028680443763733
Loss: 0.8722593784332275
Loss: 0.7521764039993286
Loss: 0.8125848174095154
Loss: 0.8445379734039307
Loss: 0.6921254396438599
Loss: 0.7250329852104187
Loss: 1.0441563129425049
Loss: 0.7678186297416687
Loss: 1.6994214057922363
Loss: 0.776030957698822
Loss: 0.8051391243934631
Loss: 1.5692933797836304
Loss: 0.7387626767158508
Loss: 1.3219749927520752
Loss: 1.0039492845535278
Loss: 0.583753764629364
Loss: 0.9799256324768066
Loss: 0.9047141075134277
Loss: 0.8090569376945496
Loss: 0.8162233829498291
Loss: 0.9321215152740479
Loss: 1.0924006700515747
Loss: 1.547302484512329
Loss: 0.7094773054122925
Loss: 0.7079649567604065
Loss: 0.5806373953819275
Loss: 0.8238936066627502
Loss: 0.5593217015266418
Loss: 0.8740336894989014
Loss: 0.843019962310791
Loss: 0.6610828638076782
Loss: 0.976271390914917
Loss: 0.7722246050834656
Loss: 0.5995108485221863
Loss: 0.7882837057113647
Loss: 0.971882164478302
Loss: 0.9416893720626831
Loss: 0.6967537999153137
Loss: 0.869011402130127
Loss: 0.5833185911178589
Loss: 1.2099775075912476
Loss: 1.111439824104309
Loss: 0.8047168254852295
Loss: 0.9576407670974731
Loss: 0.7909677624702454
Loss: 0.9925349950790405
Loss: 1.3109697103500366
Loss: 0.9661235213279724
Loss: 0.8388574123382568
Loss: 0.8907050490379333
Loss: 1.1219033002853394
Loss: 0.5701544880867004
Loss: 0.789114773273468
Loss: 0.6799432635307312
Loss: 1.1943809986114502
Loss: 1.1746820211410522
Loss: 1.2490389347076416
Loss: 0.7354246973991394
Loss: 0.7482067942619324
Loss: 0.795640766620636
Loss: 0.7944403886795044
Loss: 1.1108729839324951
Loss: 0.5719565153121948
Loss: 1.00534188747406
Loss: 0.7429819107055664
Loss: 0.69005286693573
Loss: 1.079997181892395
Loss: 1.323180913925171
Loss: 1.3380266427993774
Loss: 0.9348999857902527
Loss: 0.7958555817604065
Loss: 0.5601306557655334
Loss: 1.0071892738342285
Loss: 0.7865546941757202
Loss: 0.8939060568809509
Loss: 0.7227315902709961
Loss: 0.6551348567008972
Loss: 1.021740436553955
Loss: 0.9648611545562744
Loss: 0.9176861643791199
Loss: 0.5586667656898499
Loss: 0.9477649927139282
Loss: 0.6122022271156311
Loss: 0.681516170501709
Loss: 0.8514425754547119
Loss: 1.1174763441085815
Loss: 0.775972843170166
Loss: 0.6502513885498047
Loss: 0.6730990409851074
Loss: 0.7149274945259094
Loss: 0.6781140565872192
Loss: 0.8743259310722351
Loss: 0.9059266448020935
Loss: 0.8298972845077515
Loss: 0.8933514952659607
Loss: 0.6629049777984619
Loss: 0.8214425444602966
Loss: 0.7711682319641113
Loss: 0.9919276237487793
Loss: 0.6741620898246765
Loss: 1.4971401691436768
Loss: 0.57517009973526
Loss: 0.8414737582206726
Loss: 0.8474171757698059
Loss: 0.6625634431838989
Loss: 1.031374216079712
Loss: 0.8004299402236938
Loss: 1.3043006658554077
Loss: 0.9497361779212952
Loss: 0.8769400119781494
Loss: 1.1713382005691528
Loss: 1.1180627346038818
Loss: 0.707669734954834
Loss: 0.9224296808242798
Loss: 1.059447169303894
Loss: 1.1569066047668457
Loss: 0.7386132478713989
Loss: 0.6296594142913818
Loss: 1.0424741506576538
Loss: 0.9419296979904175
Loss: 0.6745895743370056
Loss: 1.0979670286178589
Loss: 0.6683512926101685
Loss: 0.46167972683906555
Loss: 0.7502115964889526
Loss: 0.6977225542068481
Loss: 0.7102975249290466
Loss: 0.9705597758293152
Loss: 0.7061092257499695
Loss: 0.7463416457176208
Loss: 0.8793056607246399
Loss: 0.7130594253540039
Loss: 0.8102577924728394
Loss: 1.1045202016830444
Loss: 1.0515810251235962
Loss: 0.6073160767555237
Loss: 0.8124553561210632
Loss: 1.3563568592071533
Loss: 0.670296311378479
Loss: 0.7660623788833618
Loss: 0.705219566822052
Loss: 1.0140666961669922
Loss: 0.61520916223526
Loss: 0.8402145504951477
Loss: 0.7608936429023743
Loss: 2.0747523307800293
Loss: 0.831229567527771
Loss: 0.6460816860198975
Loss: 0.8982111811637878
Loss: 0.5481370091438293
Loss: 0.9021315574645996
Loss: 0.7824054956436157
Loss: 1.2725931406021118
Loss: 0.77163165807724
Loss: 1.0254559516906738
Loss: 0.7106895446777344
Loss: 0.8671072721481323
Loss: 0.8716784715652466
Loss: 0.8549805283546448
Loss: 1.1941442489624023
Loss: 1.0415228605270386
Loss: 1.4268959760665894
Loss: 1.162760853767395
Loss: 1.2392476797103882
Loss: 0.6977691054344177
Loss: 0.6267500519752502
Loss: 0.8615598678588867
Loss: 0.8399212956428528
Loss: 1.0924410820007324
Loss: 1.1793802976608276
Loss: 1.0979218482971191
Loss: 0.7142661809921265
Loss: 0.9588887691497803
Loss: 1.1187536716461182
Loss: 0.9323568940162659
Loss: 0.6241998672485352
Loss: 0.667299747467041
Loss: 0.5864428877830505
Loss: 1.0061208009719849
Loss: 0.848665714263916
Loss: 0.8997944593429565
Loss: 1.4668363332748413
Loss: 0.976216197013855
Loss: 0.7155629992485046
Loss: 0.8339175581932068
Loss: 0.781819760799408
Loss: 0.9899125695228577
Loss: 0.9949612617492676
Loss: 0.8685347437858582
Loss: 0.7700948715209961
Loss: 0.7414076328277588
Loss: 0.8412302732467651
Loss: 0.9491223096847534
Loss: 0.9108503460884094
Loss: 0.8327219486236572
Loss: 1.1209330558776855
Loss: 0.6262702941894531
Loss: 0.7927688956260681
Loss: 0.5936712026596069
Loss: 1.0919921398162842
Loss: 0.8066765069961548
Loss: 0.6990624070167542
Loss: 0.8804552555084229
Loss: 0.5805823802947998
Loss: 0.8188803791999817
Loss: 0.9278132915496826
Loss: 0.8518646955490112
Loss: 0.6303753852844238
Loss: 0.9214684367179871
Loss: 0.8584080338478088
Loss: 1.0304993391036987
Loss: 0.7589939832687378
Loss: 0.9020643830299377
Loss: 1.2111518383026123
Loss: 1.0489643812179565
Loss: 0.7340939044952393
Loss: 0.6205451488494873
Loss: 1.0673530101776123
Loss: 0.7504695653915405
Loss: 0.666881263256073
Loss: 0.9937220215797424
Loss: 0.8459396362304688
Loss: 0.8824092745780945
Loss: 0.9054270386695862
Loss: 0.5192790031433105
Loss: 0.7334349751472473
Loss: 0.9799624681472778
Loss: 1.0584379434585571
Loss: 0.6865001320838928
Loss: 0.8051397800445557
Loss: 0.9467524290084839
Loss: 0.8337962627410889
Loss: 0.5262500643730164
Loss: 0.6371683478355408
Loss: 0.9590938687324524
Loss: 1.086845874786377
Loss: 0.8903661370277405
Loss: 0.8768320083618164
Loss: 0.7212462425231934
Loss: 0.9004424810409546
Loss: 0.7464139461517334
Loss: 0.7529594302177429
Loss: 1.0132925510406494
Loss: 1.0233049392700195
Loss: 0.7590461373329163
Loss: 0.6451581120491028
Loss: 0.8653897643089294
Loss: 0.9847288131713867
Loss: 0.5767461061477661
Loss: 0.733451247215271
Loss: 0.7117238640785217
Loss: 0.6836723685264587
Loss: 0.5856602787971497
Loss: 1.232988953590393
Loss: 0.9564592838287354
Loss: 0.8118444085121155
Loss: 0.7279089689254761
Loss: 1.2065925598144531
Loss: 1.0320231914520264
Loss: 0.7773949503898621
Loss: 0.8425804972648621
Loss: 1.3112244606018066
Loss: 1.0944626331329346
Loss: 0.9397010207176208
Loss: 0.7659670114517212
Loss: 0.6821001768112183
Loss: 0.7611058950424194
Loss: 0.891141951084137
Loss: 1.0890213251113892
Loss: 1.2047220468521118
Loss: 1.0424014329910278
Loss: 0.9872820377349854
Loss: 0.8207447528839111
Loss: 1.0254158973693848
Loss: 0.9277880787849426
Loss: 1.04047429561615
Loss: 0.9446983933448792
Loss: 0.7891526222229004
Loss: 0.5241339206695557
Loss: 0.6748109459877014
Loss: 0.5768741369247437
Loss: 0.7759105563163757
Loss: 1.132040023803711
Loss: 1.375063419342041
Loss: 0.5429614782333374
Loss: 1.0500528812408447
Loss: 0.8858404755592346
Loss: 1.2272294759750366
Loss: 1.9005334377288818
Loss: 0.6034359931945801
Loss: 0.7794085741043091
Loss: 0.8311834335327148
Loss: 1.0661356449127197
Loss: 0.9620906114578247
Loss: 1.2941153049468994
Loss: 0.988316535949707
Loss: 1.087978720664978
Loss: 0.5648202896118164
Loss: 1.1066648960113525
Loss: 0.725816547870636
Loss: 0.607001006603241
Loss: 0.6198879480361938
Loss: 0.7224195599555969
Loss: 0.7546201944351196
Loss: 0.7614554166793823
Loss: 0.854751467704773
Loss: 0.7644112706184387
Loss: 0.7622464299201965
Loss: 1.2315690517425537
Loss: 0.7050625085830688
Loss: 0.8925219178199768
Loss: 1.2348650693893433
Loss: 0.6885274648666382
Loss: 0.9343490600585938
Loss: 1.0111840963363647
Loss: 0.6754315495491028
Loss: 1.0899643898010254
Loss: 1.0863651037216187
Loss: 0.6479583978652954
Loss: 0.7064804434776306
Loss: 0.9196555018424988
Loss: 0.7183856964111328
Loss: 0.9615732431411743
Loss: 1.033795714378357
Loss: 0.890685498714447
Loss: 0.8863078355789185
Loss: 1.1138578653335571
Loss: 1.2296935319900513
Loss: 1.146927833557129
Loss: 0.7549277544021606
Loss: 0.7315452098846436
Loss: 0.6072543263435364
Loss: 0.7722539305686951
Loss: 0.9287182092666626
Loss: 0.8553401827812195
Loss: 0.895800769329071
Loss: 0.5647599697113037
Loss: 1.017560362815857
Loss: 0.8367342948913574
Loss: 0.8548362851142883
Loss: 0.6268029808998108
Loss: 1.1976972818374634
Loss: 0.8904753923416138
Loss: 1.0770509243011475
Loss: 0.6916428208351135
Loss: 0.6497384905815125
Loss: 0.9274011254310608
Loss: 0.7870333194732666
Loss: 0.8809458613395691
Loss: 0.9018659591674805
Loss: 0.8375487327575684
Loss: 0.5705377459526062
Loss: 0.7920972108840942
Loss: 0.534081757068634
Loss: 0.8040053844451904
Loss: 0.7014872431755066
Loss: 1.2461223602294922
Loss: 1.3003513813018799
Loss: 1.0386080741882324
Loss: 0.7399464845657349
Loss: 1.2204521894454956
Loss: 0.8801447749137878
Loss: 0.9897302985191345
Loss: 0.574760913848877
Loss: 1.059263825416565
Loss: 0.9678451418876648
Loss: 0.8765963912010193
Loss: 0.8327770829200745
Loss: 1.0514261722564697
Loss: 0.9704915881156921
Loss: 0.7873833775520325
Loss: 0.6829853653907776
Loss: 0.857018768787384
Loss: 0.959047257900238
Loss: 1.2092288732528687
Loss: 1.7449359893798828
Loss: 0.8418934345245361
Loss: 0.9388085007667542
Loss: 1.0748674869537354
Loss: 0.703702986240387
Loss: 0.7541993260383606
Loss: 0.7666323184967041
Loss: 1.018947720527649
Loss: 0.7621780037879944
Loss: 1.1168934106826782
Loss: 0.8387331962585449
Loss: 0.6841564178466797
Loss: 0.9424836039543152
Loss: 0.9192109107971191
Loss: 0.9396294951438904
Loss: 1.0373024940490723
Loss: 1.1630364656448364
Loss: 1.0001639127731323
Loss: 0.9558773636817932
Loss: 1.0685744285583496
Loss: 0.9751801490783691
Loss: 0.9098658561706543
Loss: 0.77012038230896
Loss: 0.7596754431724548
Loss: 0.5069338083267212
Loss: 0.7184725999832153
Loss: 0.5885892510414124
Loss: 0.7948355674743652
Loss: 1.0678277015686035
Loss: 0.7994868755340576
Loss: 1.1319563388824463
Loss: 1.0295910835266113
Loss: 0.9147792458534241
Loss: 0.7616912722587585
Loss: 0.8028551340103149
Loss: 0.8018072247505188
Loss: 0.8276918530464172
Loss: 0.7037150859832764
Loss: 0.9489409923553467
Loss: 0.7275127172470093
Loss: 0.5306674838066101
Loss: 0.9715391993522644
Loss: 0.9587855935096741
Loss: 0.7933416366577148
Loss: 1.066654920578003
Loss: 0.8102474212646484
Loss: 0.7250531911849976
Loss: 0.709024965763092
Loss: 1.2801487445831299
Loss: 0.6038312315940857
Loss: 1.0100295543670654
Loss: 1.4331092834472656
Loss: 0.5636396408081055
Loss: 1.2976984977722168
Loss: 0.7766773700714111
Loss: 1.0647207498550415
Loss: 0.8375976085662842
Loss: 1.034733533859253
Loss: 0.7877716422080994
Loss: 1.0907716751098633
Loss: 0.7037932276725769
Loss: 0.7745352983474731
Loss: 0.9338580965995789
Loss: 0.834398090839386
Loss: 0.9683565497398376
Loss: 0.9899995923042297
</code></pre>
</div>
</div>
<div id="2e28f872" class="cell markdown" id="2e28f872">
<h3 id="и-в-последний-раз-сэмплируем">И в последний раз сэмплируем</h3>
<p><strong>Важно:</strong> теперь у нас появляется возможно сэмплировать
детерминистично с помощью оригинального солвера DDIM за 4 шага. Так что
возвращаем сэмплирование исходным pipe-ом.</p>
<p>Ниже прикрепляем референс и напомним, что у вас картинки могут
отличаться и быть чуть хуже/лучше. <img
src="https://storage.yandexcloud.net/yandex-research/cvweek-cd-task-images/reference-multi-cd.png"
alt="img" /></p>
</div>
<div id="1a1239eb-4d91-4bfc-a69d-bb2e7776892c" class="cell code"
data-execution_count="44"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-06T01:57:15.987249Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-06T01:57:15.986906Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-06T01:57:58.022664Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-06T01:57:58.021751Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-06T01:57:15.987220Z&quot;}">
<div class="sourceCode" id="cb75"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>pipe.unet <span class="op">=</span> cm_unet.<span class="bu">eval</span>().to(torch.float16)</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> cm_unet.active_adapter <span class="op">==</span> <span class="st">&#39;multi-cd&#39;</span></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>guidance_scale <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> prompt <span class="kw">in</span> validation_prompts:</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>    generator <span class="op">=</span> torch.Generator(device<span class="op">=</span><span class="st">&quot;cuda&quot;</span>).manual_seed(<span class="dv">1</span>)</span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> consistency_sampling(</span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a>        pipe,</span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a>        prompt,</span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a>        num_inference_steps<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a>        generator<span class="op">=</span>generator,</span>
<span id="cb75-14"><a href="#cb75-14" aria-hidden="true" tabindex="-1"></a>        num_images_per_prompt<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb75-15"><a href="#cb75-15" aria-hidden="true" tabindex="-1"></a>        guidance_scale<span class="op">=</span>guidance_scale</span>
<span id="cb75-16"><a href="#cb75-16" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb75-17"><a href="#cb75-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-18"><a href="#cb75-18" aria-hidden="true" tabindex="-1"></a>    visualize_images(images)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb76"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;aaf555a9ff36484ca261bb61797534ae&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb77"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;383d106844794838a9cb221184121a0e&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb78"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;1b34181e142e4b37a8cc2aaafd5ff21f&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb79"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;1537af8a60f14ac685bb2647f7edbc32&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb80"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;015436347a4546539334b8d41a97b31b&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb81"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;01232e2d6f284c4aaecf6f9e109edb0e&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb82"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;0d61f161614348cc8fd3c60c34dc1f5a&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb83"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;a3eb81076b7149b38c39acc407117c0c&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/3f066448ba741ae023ee0884a91b6ae10f6a9468.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/5e08d5556d17055aa6f7932a28512ea3990ee13f.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/e2946da8faea80834d9ae36b34611faaa78e94f7.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/ebb9126601d3859963934ba3c3779e823f126c6d.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/c8ea5c1080b6bd02d6731a62b4dbf3b0750f156f.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/24e85f8a718bfdfd29aeac8b3bccc018809dc91b.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/79f9aa5247cbfb20c938f54bf2e5bef5929d20bd.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/1febdc18bcbfcc8f4580effb57fe8bd10a40e8d6.png" /></p>
</div>
</div>
<div id="403e782d" class="cell markdown" id="403e782d">
<h2 id="задание-8">Задание №8</h2>
<p>Все, что осталось сделать - это загрузить ваши обученные модельки на
huggingface_hub. Это очень популярный и удобный способ для хранения
моделей, которые легко можно загружать и подставлять в модель. Другими
словами GitHub для моделей и датасетов.</p>
<p>1) Создайте аккаунт на <a
href="huggingface.co">huggingface.co</a></p>
<p>2) Получите свой HF токен, который можно получить здесь: <a
href="https://huggingface.co/settings/tokens"
class="uri">https://huggingface.co/settings/tokens</a></p>
<p>3) Создайте репозиторий для ваших моделями <a
href="https://huggingface.co/new"
class="uri">https://huggingface.co/new</a></p>
<p><strong>Важно: перед отправкой нотбука на проверку, не забудьте
удалить свой HF токен!</strong></p>
</div>
<div id="7c8e08bf" class="cell code" data-execution_count="48"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-06T02:01:50.631934Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-06T02:01:50.631207Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-06T02:02:00.869911Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-06T02:02:00.869093Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-06T02:01:50.631900Z&quot;}"
id="7c8e08bf">
<div class="sourceCode" id="cb84"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>cm_unet.push_to_hub(</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;sudakovilya/cv_week&#39;</span>,</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>    token<span class="op">=</span><span class="st">&#39;...&#39;</span></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb85"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;5ee1c6a1e269497db3f278e514f53aba&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb86"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;14a64178584340bc969645c96310dec4&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb87"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;c8302ca2a5074fe38ca7b44f480b2f21&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb88"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;2ad162af7a924b23bb01fc323bffbecc&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output execute_result" data-execution_count="48">
<pre><code>CommitInfo(commit_url=&#39;https://huggingface.co/sudakovilya/cv_week/commit/3d83fb0f8b48b0e2b3cefc75a477c60acfeb1180&#39;, commit_message=&#39;Upload model&#39;, commit_description=&#39;&#39;, oid=&#39;3d83fb0f8b48b0e2b3cefc75a477c60acfeb1180&#39;, pr_url=None, pr_revision=None, pr_num=None)</code></pre>
</div>
</div>
<div id="214be7df" class="cell markdown" id="214be7df">
<p>Пример, как должен выглядеть результат выполнения команды: <a
href="https://huggingface.co/dbaranchuk/cv-week-final-task-example"
class="uri">https://huggingface.co/dbaranchuk/cv-week-final-task-example</a></p>
<p>Давайте проверим, что загрузка модели корректно работает.</p>
</div>
<div id="b9caee95" class="cell code" data-execution_count="49"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-06T02:02:15.558850Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-06T02:02:15.558000Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-06T02:02:20.527337Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-06T02:02:20.526292Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-06T02:02:15.558813Z&quot;}"
id="b9caee95">
<div class="sourceCode" id="cb90"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> peft <span class="im">import</span> PeftModel</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>loaded_cm_unet <span class="op">=</span> PeftModel.from_pretrained(</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>    unet,</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;sudakovilya/cv_week&#39;</span>,</span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>    token<span class="op">=</span><span class="st">&#39;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&#39;</span>,</span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>    subfolder<span class="op">=</span><span class="st">&#39;multi-cd&#39;</span>,</span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>    adapter_name<span class="op">=</span><span class="st">&quot;multi-cd&quot;</span>,</span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb91"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;e1aa1fb116c842eb95ad35a98519e838&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb92"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;dc652f3345b04376af1eb8bbd9e0f7ab&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<div id="051a6090-ac7f-4ed5-83c3-3a5d3b49c9df" class="cell code"
data-execution_count="50"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-06T02:02:22.087886Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-06T02:02:22.087541Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-06T02:02:22.138369Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-06T02:02:22.137500Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-06T02:02:22.087857Z&quot;}">
<div class="sourceCode" id="cb93"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>pipe.unet <span class="op">=</span> loaded_cm_unet.<span class="bu">eval</span>().to(torch.float16)</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> loaded_cm_unet.active_adapter <span class="op">==</span> <span class="st">&#39;multi-cd&#39;</span></span></code></pre></div>
</div>
<div id="ad678713" class="cell code" data-execution_count="51"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-12-06T02:02:34.723112Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-12-06T02:02:34.722040Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-12-06T02:03:17.580027Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-12-06T02:03:17.579205Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-12-06T02:02:34.723077Z&quot;}"
id="ad678713">
<div class="sourceCode" id="cb94"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>pipe.unet <span class="op">=</span> loaded_cm_unet.<span class="bu">eval</span>().to(torch.float16)</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> loaded_cm_unet.active_adapter <span class="op">==</span> <span class="st">&#39;multi-cd&#39;</span></span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>guidance_scale <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> prompt <span class="kw">in</span> validation_prompts:</span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a>    generator <span class="op">=</span> torch.Generator(device<span class="op">=</span><span class="st">&quot;cuda&quot;</span>).manual_seed(<span class="dv">1</span>)</span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> consistency_sampling(</span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a>        pipe,</span>
<span id="cb94-11"><a href="#cb94-11" aria-hidden="true" tabindex="-1"></a>        prompt,</span>
<span id="cb94-12"><a href="#cb94-12" aria-hidden="true" tabindex="-1"></a>        num_inference_steps<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb94-13"><a href="#cb94-13" aria-hidden="true" tabindex="-1"></a>        generator<span class="op">=</span>generator,</span>
<span id="cb94-14"><a href="#cb94-14" aria-hidden="true" tabindex="-1"></a>        num_images_per_prompt<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb94-15"><a href="#cb94-15" aria-hidden="true" tabindex="-1"></a>        guidance_scale<span class="op">=</span>guidance_scale</span>
<span id="cb94-16"><a href="#cb94-16" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb94-17"><a href="#cb94-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-18"><a href="#cb94-18" aria-hidden="true" tabindex="-1"></a>    visualize_images(images)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb95"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;86e71a13066941fa91c14dffad30943a&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb96"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;137943e6adf04acc8816b7344261f999&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb97"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;3e41c1b18894469ab13a6f4142aa6622&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb98"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;f56cbc63bca6401c860ff26e0926d9c3&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb99"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;91f0bf87fedb41ddbb9976a67c8e5602&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb100"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;ebe4dd7465254f3e8e72daad6e936e0f&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb101"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;fe3092c48bff4f24b81e22638ee737d1&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb102"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;f7a4cfdb458e46c5a9d19c4aea8a159e&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/d91e2429901ffa8a489e41cd100dca945532ad53.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/e84efbc5482756d68e3e1f268cce50b7b5c67582.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/2c346503fc96c62b1960a86ad49f0dbfedc32e4c.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/263de51669c976f1259d55bb6b5def7ef3438f8a.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/3a0690b0c40281e8496d49e986a73766e5339a42.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/aae08c94ac0334ea65fa76ecbeda8715bb360409.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/a2e3e1a19bf7c7a259b6e6099088c5c083a737f6.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_5f7d909975764f50976e9939a3c43114/429e0da750ceabdea9955bdae68702b30ee5915c.png" /></p>
</div>
</div>
<div id="508112b9" class="cell markdown" id="508112b9">
<p><strong>На этом все! Ура!</strong></p>
<div>
<p><img src="https://storage.yandexcloud.net/yandex-research/cvweek-cd-task-images/yoda.jpg" width=400>
<div></p>
</div>
<div id="721fcfe5" class="cell markdown" id="721fcfe5">
<h3
id="ps-некоторые-примеры-плохих-генераций-которые-могут-возникать-при-выполнении-задания">P.S.
Некоторые примеры плохих генераций, которые могут возникать при
выполнении задания</h3>
<h4 id="неправильный-сэмплинг">Неправильный сэмплинг</h4>
<p><img
src="https://storage.yandexcloud.net/yandex-research/cvweek-cd-task-images/fail_case_1.jpg"
alt="img" /> <img
src="https://storage.yandexcloud.net/yandex-research/cvweek-cd-task-images/fail_case_2.jpg"
alt="img" /></p>
<h4 id="ошибки-в-обучении">Ошибки в обучении</h4>
<p><img
src="https://storage.yandexcloud.net/yandex-research/cvweek-cd-task-images/fail_case_3.jpg"
alt="img" /> <img
src="https://storage.yandexcloud.net/yandex-research/cvweek-cd-task-images/fail_case_4.jpg"
alt="img" /></p>
<h4 id="необученная-модель">Необученная модель</h4>
<p><img
src="https://storage.yandexcloud.net/yandex-research/cvweek-cd-task-images/fail_case_5.jpg"
alt="img" /></p>
</div>
</body>
</html>
